{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8144fc94",
   "metadata": {},
   "source": [
    "# XAI 2024 TP5\n",
    "\n",
    "## PostHoc methods - Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de738208",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Author: Arthur Babey\n",
    "\n",
    "Due: 30.04.2025, 23h59\n",
    "\n",
    "- Professor: Carlos Peña (<a href=\"mailto:carlos.pena@heig-vd.ch\">carlos.pena@heig-vd.ch</a>)\n",
    "- Assistant 2024: Arthur Babey (<a href=\"mailto:arthur.babey@heig-vd.ch\">arthur.babey@heig-vd.ch</a>)\n",
    "\n",
    "\n",
    "Date: Spring 2025\n",
    "\n",
    "* You will need to fill code and answer questions in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50a1e6",
   "metadata": {},
   "source": [
    "You have a folder named XAI_TP5_2024 that is structured in the following way:\n",
    "\n",
    "\n",
    "XAI_TP4_2025_Tabular/\n",
    "\n",
    "\tdata/\n",
    "\t\twinequality-red.csv\n",
    "        \n",
    "\tmodel/\n",
    "\t\tregressor2025.pkl\n",
    "                \n",
    "\tXAI_TP4_2025_NOM_PRENOM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d08883",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Instructions\n",
    "\n",
    "During this TP we will use the (same as TP3) [dataset](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009) which contains various measurements and ratings for the wine quality.\n",
    "\n",
    "Your tasks will be to complete the code, generate plots, and answer questions related to the following goals:\n",
    "\n",
    "Goal :\n",
    "\n",
    "0. Explore : explore and preprocess the dataset \n",
    "1. Model : create a regression model and compute metrics \n",
    "2. Global explanation : compute global feature importance values and generate plot\n",
    "3. Local explanation : compute local feature importance to understand the model behaviour at instance level\n",
    "4. Open the black box : explain a new model using the different methods \n",
    "5. Compute Lime : compute lime values from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bde7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import lime\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f1eca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Explore and prepare the dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The first step is to read and split our dataset into training and test parts. \n",
    "\n",
    "- If necessary (mac or linux) modify the path of your original dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58657bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHs and seed for reproducibility\n",
    "\n",
    "dataset_path = os.path.join(\"data\", \"winequality-red.csv\")\n",
    "SEED = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af00363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data inot a pandas dataframe\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "column_names = list(df.columns)\n",
    "print(df[\"quality\"].unique())\n",
    "# substract quality by three to reduce the labels size \n",
    "df[\"quality\"] = df[\"quality\"]-3\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can have a look at the label distribution\n",
    "df['quality'].plot(kind='density')\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into a train and a test set \n",
    "# the quality feature will be our label vector (y)\n",
    "\n",
    "\n",
    "X = df.drop(\"quality\", axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50073eba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Modeling with a standard ML method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716f0e3-d358-4f72-a519-0ec16187d271",
   "metadata": {},
   "source": [
    "In the code below you have an implementation of a machine learning model, you will need to : \n",
    "\n",
    "1. Train a model and make a prediction with it\n",
    "2. Compute metrics to evaluate your model\n",
    "\n",
    "\n",
    "### Regression or Classification with a Decision Tree\n",
    "\n",
    "Since the output variables are ordered (with 0 being low quality and 5 being high quality), we can perform regression using the DecisionTreeRegressor from the scikit-learn API. : [regressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html).\n",
    "\n",
    "### Complete the code below to : \n",
    "\n",
    "1. Create a model using DecisionTree (use random_state = SEED) for reproducibility\n",
    "2. Train it with the training data \n",
    "3. Make prediction on the test set\n",
    "4. Compute, print and interpet the (root) mean squared error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bfd24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE \n",
    "# name your model \"regressor\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE \n",
    "# print the metrics here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279faf7",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /4 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fed808",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Global explanation : Feature Importance exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fce9dd-6056-4a58-8199-bcbea15f04b7",
   "metadata": {},
   "source": [
    "Now that we have a model we can try to understand how it is working\n",
    "\n",
    "In the code below, you will need to : \n",
    "\n",
    "1. Compute Feature Importance using : \n",
    "    - Built in feature importance method\n",
    "    - Other Post-Hoc methods\n",
    "2. Plot you result \n",
    "3. Compare your result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49627b85",
   "metadata": {},
   "source": [
    "### 2.1 Built in Feature Importance exploration :\n",
    "\n",
    "\n",
    "Here's an example of how to compute feature importance using built-in methods. Many machine learning models have a built-in method to compute feature importance, such as tree models, SVMs, XGBoost, etc. However, this method is limited and often non-consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a748b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you failed to train a regressor model, you can continue the lab by loading this one by running this cell.\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "# Load the regressor model from the specified path\n",
    "regressor2 = load('model/regressor2025.pkl')\n",
    "\n",
    "print(\"Regressor2 model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances\n",
    "re_importances = regressor.feature_importances_\n",
    "\n",
    "# The higher values means the more important is the feature. The importance of a feature is computed as the\n",
    "# Total reduction of the criterion brought by that feature known as Gini importance\n",
    "\n",
    "\n",
    "# Print the feature importances\n",
    "for i, feature in enumerate(X.columns):\n",
    "    print(f\"Regressor importance - {feature:<20}: {re_importances[i]:.2f}\")\n",
    "\n",
    "# check that the sum of importance = 1\n",
    "print(f\"Regressor's importances sum is = {re_importances.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f14260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with one subplot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot the second set of data\n",
    "sorted_idx = re_importances.argsort()[::-1]\n",
    "sorted_importances = re_importances[sorted_idx][::-1]\n",
    "sorted_features = X.columns[sorted_idx][::-1]\n",
    "\n",
    "ax.barh(sorted_features, sorted_importances)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_title('Regressor Feature Importances')\n",
    "ax.yaxis.set_ticks(sorted_features)\n",
    "ax.tick_params(axis='x', labelsize=8)\n",
    "ax.set_yticklabels(sorted_features, fontsize=8)\n",
    "ax.set_xlim([0, 0.5])\n",
    "\n",
    "# Adjust the layout of the subplot\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85c064",
   "metadata": {},
   "source": [
    "---\n",
    "#### Note :\n",
    "\n",
    "- Ok so this is interesting but : we can do **better**. We do not have local explanation, we can not see the **heterogeneity** in the population nor the **interactions** between features\n",
    "\n",
    "- We need to use XAI methods to have a better understanding at what's going on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad178c32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2 Explaining Feature Importances with Post-Hoc Methods\n",
    "\n",
    "- To gain deeper insights into both global and local feature importances, we will use **post-hoc** methods. These techniques are designed to explain the behavior of complex models and how they make predictions.\n",
    "\n",
    "- We will specifically use two post-hoc methods: **LIME** and **SHAP**, both of which are **model-agnostic**—meaning they can provide explanations for any type of model.\n",
    "\n",
    "- Complete the code below to compute and print the **global SHAP values** on the **test set**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b04c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create explainer object on our regressor model\n",
    "explainer_re = shap.TreeExplainer(regressor, feature_names=X_test.columns.tolist())\n",
    "\n",
    "explainer_re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ef444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute shap values on the scaled test set\n",
    "shap_values = explainer_re.shap_values(X_test)\n",
    "\n",
    "# we can have a look at the shap values for each instance in the test set\n",
    "pd.DataFrame(shap_values, columns=X_test.columns.tolist()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be0530",
   "metadata": {},
   "source": [
    "### Complete the code below : \n",
    "\n",
    "Now make a **bar plot** first and then a **beeswarm plot** of the shap values using the [shap plot API](https://shap.readthedocs.io/en/latest/api_examples.html#explainers) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bfcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "# generate a bar plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "# generate a dot plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5a4a1",
   "metadata": {},
   "source": [
    "### Questions : \n",
    "\n",
    "\n",
    "How shap values are transformed before the bar plot ?\n",
    "\n",
    "\n",
    "And the beeswarm plot ?\n",
    "    \n",
    "    \n",
    "What benefits has the beeswarm plot ?     \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ef403",
   "metadata": {},
   "source": [
    "*Answers:*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b484cf",
   "metadata": {},
   "source": [
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /6 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a871d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2.1 SHAP Dependence Plot\n",
    "\n",
    "SHAP allows us to visualize the **dependence** between a feature's value and its SHAP value using the modern `shap.plots.scatter` function.\n",
    "\n",
    "This plot helps us understand how a feature contributes to the model’s output across the dataset, and we can optionally color the points by another feature to explore **interactions**.\n",
    "\n",
    "> Choose a feature to explain (e.g., `\"alcohol\"`), and use `shap.plots.scatter` to plot its SHAP values.  \n",
    "> \n",
    ">Try adding a `color` argument with another feature (e.g., `\"sulphates\"`) to explore interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE \n",
    "# make dependence plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111c79f",
   "metadata": {},
   "source": [
    "### Questions :\n",
    "\n",
    "Describe your plot and indicate what can we get from these plots ?  \n",
    "\n",
    "\n",
    "What can we get from the color axis here ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e8a18",
   "metadata": {},
   "source": [
    "*Answers:*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea2453",
   "metadata": {},
   "source": [
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /4 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae34fb",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Local explanation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3e7ea-7698-48d8-a44c-84d135af1952",
   "metadata": {},
   "source": [
    "### Local explanation with SHAP\n",
    "\n",
    "SHAP can also be used to make **local** explanation i.e compute shap values for one instance \n",
    "\n",
    "A model is often use to make prediction on new instance thus it is important to be able to explain it \n",
    "\n",
    "### Complete the code \n",
    "\n",
    "1. Using regressor compute the SHAP value for the instance define in the next cell\n",
    "\n",
    "2. Print the prediction and the true label \n",
    "\n",
    "3. Use [shap.plot.waterfall](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.waterfall_plot.html) to plot the SHAP values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ba695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recompute shap values (needed to use waterfall plot)\n",
    "shap_values = explainer_re(X_test)\n",
    "\n",
    "# we define an instance to investigate\n",
    "index = 66\n",
    "X_test.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE \n",
    "# print the prediction by *regressor* and the true label for instance index=66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e54749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "# make a waterfall plot of the prediction index = 66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad351e8",
   "metadata": {},
   "source": [
    "### Question :\n",
    "\n",
    "Describe what the waterfall plot is showing ? \n",
    "\n",
    "\n",
    "What does mean the label on the x-axis : E[f(x)] ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47810ca",
   "metadata": {},
   "source": [
    "*Answers:*\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa3da9",
   "metadata": {},
   "source": [
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /4 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8a993",
   "metadata": {},
   "source": [
    "### 3.2 Local explanation with LIME \n",
    "\n",
    "[Lime](https://github.com/marcotcr/lime) is another widely used method to compute local explanation. It works completely differently than SHAP but we can also use it to compute local importance per features.  \n",
    "\n",
    "#### Complete the code : \n",
    "\n",
    "1. Use Lime  (the lime.lime_tabular.LimeTabularExplainer module) to create a lime explainer using the training data\n",
    "2. Use lime explainer.explain_instance to make a plot for instance index=66\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE \n",
    "# create a lime explainer using the training data\n",
    "\n",
    "explainer = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb637caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test.iloc[index], \n",
    "    predict_fn=regressor.predict\n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deabf73",
   "metadata": {},
   "source": [
    "### Questions : \n",
    "\n",
    "Compare your Lime and SHAP result : \n",
    "\n",
    "*Answer:*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30eb07",
   "metadata": {},
   "source": [
    "### Questions : \n",
    "\n",
    "\n",
    "Conceptually what are the differences you might found between global and local prediction ? \n",
    "\n",
    "\n",
    "Imagine you are doctor and you are using a model to classify general health based on some measurements, you now have to explain to your patient the outcome of your model : conceptually how could you use global prediction to explain your patient ? and how could you use local prediction ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15b9d5",
   "metadata": {},
   "source": [
    "*Answers:*\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571d77d",
   "metadata": {},
   "source": [
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /6 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71c457",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Open the black box \n",
    "\n",
    "Now that we have mutliple tools to understand a model's prediction we will focus on new instance and try to really understand what is going on by opening the black box \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a91c0-756d-4dff-b64a-00e2cba1ec94",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Explain prediction on a new vine : \n",
    "\n",
    "Here we define a new vine called *new_vine* by adding noise to the mean of our test sample. Then I set the alcohol value to 16. This is a **very** high and unusual value for a vine thus this should have an clear impact on the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ccd90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's create a new vine data by adding noise to the training data mean\n",
    "np.random.seed(1)\n",
    "\n",
    "new_vine = X_test.mean(axis=0) \n",
    "gap = np.array(X_test.mean(axis=0)) \n",
    "noise = np.random.uniform(low=-gap*0.5, high=gap*0.5, size=gap.shape)\n",
    "\n",
    "# we set the alcohol value to 16 (very strong vine)\n",
    "\n",
    "new_vine = new_vine + noise\n",
    "new_vine['alcohol'] = 16\n",
    "new_vine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb840fbf",
   "metadata": {},
   "source": [
    "### Question : \n",
    "\n",
    "Imagine you are a wine seller looking for new products to sell. To help you, you use your regressor model to predict how good a wine is. One day, a wine producer shows you their new wine (which we'll call \"new_vine\"). You have all the necessary data, you can use your model and XAI knowledge to decide whether or not to purchase the new wine.\n",
    "\n",
    "Using your regressor model and your XAI knowledge, decide whether or not to buy the new wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE \n",
    "# Use regressor to make a prediction (here as new_vine is a new example we do not have the true label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80489d6",
   "metadata": {},
   "source": [
    "Good news ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3542627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compute the shap value for this new vine\n",
    "\n",
    "new_vine_shap_values = explainer_re(np.array([new_vine]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2237a",
   "metadata": {},
   "source": [
    "### Complete the code below : \n",
    "\n",
    "Complete the code below to understand how each features contributed to the prediction :\n",
    "\n",
    "*hint : a plot we used before could help you*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83615d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fae395",
   "metadata": {},
   "source": [
    "### Questions : \n",
    "\n",
    "Comment the 5 quality predicted  by the model regarding the feature contribution : \n",
    "\n",
    "How the alcohol value impacted the model ? \n",
    "\n",
    "Can we have fully confidence in our black box model ? comment\n",
    "\n",
    "Use your expert knowledge (here you know that 16 alcohol degree is unusual and probably weird) to choose wether or not to buy the **new_vine**. Comment and explain your decision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083cf6cb",
   "metadata": {},
   "source": [
    "*Answers:*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691da69c",
   "metadata": {},
   "source": [
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /8 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3359ef7",
   "metadata": {},
   "source": [
    "### 4.2 Understanding Good and Bad Model Predictions\n",
    "\n",
    "#### Question:\n",
    "\n",
    "In the next cell, I provide two instances from the test set: `good_instance`, which is correctly predicted by the model, and `bad_instance`, which is poorly predicted.\n",
    "\n",
    "Explain the differences between these two instances. Why does the model perform well on `good_instance` while misclassifying `bad_instance`? You may use any methods you want, compute values, create plots, etc, to illustrate your explanation. Provide a detailed discussion on why the model performs well on one instance and poorly on the other.\n",
    "\n",
    "To ensure that the predictions match the expectations, you can use `regressor2` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e715d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_instance1 = X_test.iloc[15] #label = 4\n",
    "good_instance2 = X_test.iloc[129] #label = 1\n",
    "\n",
    "bad_instance1 = X_test.iloc[85] # label = 1 pred = 4\n",
    "bad_instance2 = X_test.iloc[111] # label = 4 pred = 1\n",
    "\n",
    "for idx in [15, 129, 85, 111]:\n",
    "\n",
    "    print(f\"The true label is {y_test.iloc[idx]} and the regressor prediction is \\\n",
    "    {regressor.predict((np.array(X_test.iloc[idx])).reshape(1,-1))[0] }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR COMMENT/ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388f94a",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /6 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be2ea5",
   "metadata": {},
   "source": [
    "---\n",
    "**Note on Interpretability vs. Causality**\n",
    "\n",
    "SHAP values and LIME like many other post-hoc explainability methods such as permutation importance, and feature importance in tree-based models — explain how a **model** uses input features to make **predictions**. \n",
    "\n",
    "They do not tell us how these features truly cause the target variable in the real world. This is a general limitation of model interpretation: even if a model is highly accurate, it might rely on spurious patterns, correlations, or proxy variables that do not reflect actual causal relationships. Therefore, explanations from a Post-Hoc method should be used to understand **model behavior**, not to infer causal mechanisms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea67fdd",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /2 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56c5c5",
   "metadata": {},
   "source": [
    "## 5. Impementing Lime step by step \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88616ec9",
   "metadata": {},
   "source": [
    "In this section we will try to compute the lime values by ourselves instead of using the library. We will use the same but simpler dataset. We threshold the quality at six to have a binary classification task (either 0 or 1) and we will use only two features. This will help us to explain and visualize the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8453c",
   "metadata": {},
   "source": [
    "Lime values can be computed in 5 steps :\n",
    "\n",
    "1. Choosing an instance\n",
    "2. Make perturbations around the instance\n",
    "3. Making predictions on the perturbed data\n",
    "4. Weighting the perturbations\n",
    "5. Training a local model \n",
    "\n",
    "If you are interested you can have a look at the [Lime paper here](https://arxiv.org/pdf/1602.04938.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892452f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same dataset we change the quality \n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "column_names = list(df.columns)\n",
    "df['quality'] = df['quality'].apply(lambda x: 0 if x < 6 else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95399668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can have a look at the label distribution => it is balance\n",
    "df['quality'].plot(kind='density')\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19963852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use only alchohol and sulphates as features to simplify \n",
    "features = ['alcohol', 'sulphates']\n",
    "X = StandardScaler().fit_transform(df[features])\n",
    "y = df['quality'].values\n",
    "\n",
    "# random split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=SEED)\n",
    "\n",
    "# create and fit a model here we will use a simple random forest classifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = classifier.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_predicted)\n",
    "\n",
    "# Let's see how well our model performed\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_predicted).ravel()\n",
    "recal = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "\n",
    "print(\"accuracy = {acc:0.3f},\\nrecall = {recal:0.3f},\\nprecision = {precision:0.3f}\".format(\n",
    "        acc=accuracy, recal=recal,precision=precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312ccc9",
   "metadata": {},
   "source": [
    "#### Step 1 : choose an instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose any instance from the test set, Xi will be the instance we will try to explain \n",
    "\n",
    "Xi = X_test[298]\n",
    "Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea4e634",
   "metadata": {},
   "source": [
    "#### Step 2 : make perturbation around the instance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed892b9",
   "metadata": {},
   "source": [
    "#### Complete the function below and use it to make perturbation\n",
    "\n",
    "You need to return X_perturb which are random points around an instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad400615",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "### COMPLETE THE FUNCTION \n",
    "\n",
    "def make_perturbations(instance, sigma=0.5, num=750, seed = 2023 ):\n",
    "    np.random.seed(seed=seed)\n",
    "    \n",
    "    \n",
    "    return\n",
    "    \n",
    "X_perturb = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ea62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 3 : Making predictions on the perturbed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "y_perturb = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc80a1",
   "metadata": {},
   "source": [
    "#### Step 4 : Weighting the perturbations\n",
    "\n",
    "Try to understand what the function is doing\n",
    "\n",
    "The kernel gives a larger weight to perturbations closer by the instance than those further away. The kernel_width sets a scale for locality: decreasing this value will give more importance to perturbations that lie closer by the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(instance, X_perturb, kernel_width):\n",
    "    distances = np.sum((instance - X_perturb)**2, axis=1)\n",
    "    weights = np.sqrt(np.exp(-(distances**2)/(kernel_width**2))) #Kernel function\n",
    "    return weights\n",
    "\n",
    "weights = get_weights(Xi, X_perturb, kernel_width=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973ad4b",
   "metadata": {},
   "source": [
    "#### Step 5 : Training a local model\n",
    "\n",
    "#### Complete the code below : \n",
    "\n",
    "Complete the get local coeffs function, you need to fit a (weighted) **linear regression model** on the perturbed and return the coefficient and the intercept of the linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "### complete the function\n",
    "\n",
    "\n",
    "def get_local_coeffs(X_perturb, y_perturb, weights):\n",
    "    local_model = \n",
    "    \n",
    "    return coefs, intercept\n",
    "\n",
    "\n",
    "\n",
    "(a,b), c = get_local_coeffs(X_perturb, y_perturb, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT THE COEFFs AND INTERCEPT\n",
    "\n",
    "print(f\"Alcohol coef : a = {a}\")\n",
    "print(f\"Sulphate coef : b = {b}\")\n",
    "print(f\"Intercept: c = {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bfa23",
   "metadata": {},
   "source": [
    "### Questions : \n",
    "\n",
    "How do you interpret the coefficient for the alcohol and the sulphates ? How did we call them before ? \n",
    "\n",
    "Can we use these values to interpret any new instance ? Why ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577bb36",
   "metadata": {},
   "source": [
    "*Answers:*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f230b3",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /7 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba455d",
   "metadata": {},
   "source": [
    "#### Visualization :\n",
    "\n",
    "The next cell should plot the step 2,3 and 4. Make change if needed to visualize the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55668c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = X_perturb[y_perturb == 0], X_perturb[y_perturb == 1]\n",
    "s1, s2 = weights[y_perturb == 0], weights[y_perturb == 1]\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (12,4))\n",
    "\n",
    "axs[0].scatter((X_perturb)[:, 0], (X_perturb)[:, 1], c=\"#e9a3c9\")\n",
    "axs[0].scatter(Xi[0], Xi[1], c=\"blue\", marker=\"o\", s=40)\n",
    "axs[0].set_xlabel(features[0])\n",
    "axs[0].set_ylabel(features[1])\n",
    "axs[0].set_title(\"step 2\")\n",
    "\n",
    "axs[1].scatter((x1)[:,0],(x1)[:,1], c=\"#e9a3c9\", alpha=0.9, label='Quality : 0')\n",
    "axs[1].scatter((x2)[:,0],(x2)[:,1], c=\"#a1d76a\", alpha=0.7, label = 'Quality: 1')\n",
    "axs[1].scatter(Xi[0],Xi[1],c=\"blue\",marker=\"o\",s=40 )\n",
    "axs[1].set_xlabel(features[0])\n",
    "axs[1].set_ylabel(features[1])\n",
    "axs[1].legend()\n",
    "axs[1].set_title(\"step 3\")\n",
    "\n",
    "\n",
    "axs[2].scatter((x1)[:,0],(x1)[:,1], c=\"#e9a3c9\", alpha=0.7, s=50*s1, label='Quality : 0')\n",
    "axs[2].scatter((x2)[:,0],(x2)[:,1], c=\"#a1d76a\", alpha=0.7, s=50*s2, label = 'Quality: 1')\n",
    "axs[2].scatter(Xi[0],Xi[1],c=\"blue\",marker=\"o\",s=40 )\n",
    "axs[2].set_xlabel(features[0])\n",
    "axs[2].set_ylabel(features[1])\n",
    "axs[2].legend()\n",
    "axs[2].set_title(\"step 4\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93fae0",
   "metadata": {},
   "source": [
    "#### Good Job ! The last questions are bonus, so answer it if you want to :) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41480e79",
   "metadata": {},
   "source": [
    "## Bonus questions : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78875b95-c975-4bc1-a52b-a97a6709798d",
   "metadata": {},
   "source": [
    "What is the local decision boundary of our binary classification task ?\n",
    "\n",
    "Can you express it mathematically ? \n",
    "\n",
    "Can you plot it ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070f8ff",
   "metadata": {},
   "source": [
    "*Answers:*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1bd52-fddb-4a17-be98-dc7d9ef40da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e89ebc85",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /3 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134092c",
   "metadata": {},
   "source": [
    "FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
