{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a54cc36",
   "metadata": {},
   "source": [
    "# XAI - 2025 - TP1 - Feature Selection\n",
    "\n",
    "\n",
    "But du TP: \n",
    "\n",
    "- Explorer plus en profondeur la sélection d'attributs (Feature Selection) dans une optique d'interprétabilité. Répondez aux questions et complétez le code directement dans le notebook et n'oubliez pas de changer le nom du fichier avec votre nom et prénom. \n",
    "\n",
    "Rendu du TP: \n",
    "\n",
    "- Durée 2 semaines\n",
    "- Mercredi 12 mars 2025 23h59, Cyberlearn\n",
    "\n",
    "Description: \n",
    "\n",
    "   - Le dataset [MILE](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE13159) contient pour ~2000 patients les données d'expression d'environ 54'000 gènes. Afin d'accélérer le début de ce TP, les features ont déjà été écrémées grâce à trois méthodes différentes (chi2, mutual_information et f_score) qui ont chacunes retourné les 5000 meilleures variables (features). \n",
    "\n",
    "Dans ce travail vous devrez: \n",
    "\n",
    "1. Comparer les features sélectionnées par les premières méthodes de filtre et en retourner un subset adéquat.\n",
    "\n",
    "     \n",
    "2. Appliquer méthodes wrapper sur le dataset choisi\n",
    "\n",
    "    a. RFE-RF\n",
    "    \n",
    "    b. RFE-SVM\n",
    "\n",
    "\n",
    "3. Entrainer un modèle et en extraire les features les plus importantes\n",
    "\n",
    "    a. Random Forest (RF)\n",
    "    \n",
    "    b. Support Vector Machine (SVM)\n",
    "    \n",
    "    \n",
    "4. Sélectionner les attributs les plus pertinents\n",
    "\n",
    "    a. Entrainer des modèles (RF et SVM) avec le dataset réduit \n",
    "\n",
    "\n",
    "5. Essayez une méthode d'ensemble pour la feature selection\n",
    "\n",
    "\n",
    "6. Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71be488",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Filter methods\n",
    "\n",
    "Trois méthodes de *features selection* ont été préalablement appliquées au dataset original afin de vous éviter un temps de calcul trop long. De ce dataset, qui contient 54'000 attributs (ou features, ou variables), chaque méthode en a retenu 5000 qui sont présents dans les trois fichiers csv joints et qui sont lus ci-dessous. \n",
    "\n",
    "- Explorez rapidement les données\n",
    "- Exécutez et comprenez le code ci-dessous et répondez aux questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d7e1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si nécessaire installez les packages suivants:\n",
    "\n",
    "#!conda install scikit-learn\n",
    "#!pip install matplotlib_venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cde1d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b03554d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the three datasets with each 5000 variables previously selected with the \n",
    "# sklearn.SelectKBest method with the following scoring functions (filters)\n",
    "\n",
    "# - mutual_information_score\n",
    "# - chi2\n",
    "# - f_classifier\n",
    "\n",
    "# Note: leukemia_class will be considered a feature and replaced at the end !\n",
    "\n",
    "features_df_mutual_5000 = pd.read_csv(\"./data/features_df_mutual_5000.csv\", index_col='ID_REF')\n",
    "features_df_chi2_5000 = pd.read_csv(\"./data/features_df_chi2_5000.csv\", index_col='ID_REF')\n",
    "features_df_fc_5000 = pd.read_csv(\"./data/features_df_fc_5000.csv\", index_col='ID_REF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13a50566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_df_mutual_5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1552256_a_at</th>\n",
       "      <th>1552257_a_at</th>\n",
       "      <th>1552275_s_at</th>\n",
       "      <th>1552287_s_at</th>\n",
       "      <th>1552348_at</th>\n",
       "      <th>1552398_a_at</th>\n",
       "      <th>1552401_a_at</th>\n",
       "      <th>1552426_a_at</th>\n",
       "      <th>1552474_a_at</th>\n",
       "      <th>...</th>\n",
       "      <th>59697_at</th>\n",
       "      <th>60471_at</th>\n",
       "      <th>65086_at</th>\n",
       "      <th>65493_at</th>\n",
       "      <th>65718_at</th>\n",
       "      <th>74694_s_at</th>\n",
       "      <th>AFFX-HUMGAPDH/M33197_3_at</th>\n",
       "      <th>AFFX-HUMGAPDH/M33197_5_at</th>\n",
       "      <th>AFFX-HUMGAPDH/M33197_M_at</th>\n",
       "      <th>leukemia_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM329407</th>\n",
       "      <td>0.361346</td>\n",
       "      <td>0.574043</td>\n",
       "      <td>0.628138</td>\n",
       "      <td>0.472343</td>\n",
       "      <td>0.516924</td>\n",
       "      <td>0.314686</td>\n",
       "      <td>0.581724</td>\n",
       "      <td>0.221830</td>\n",
       "      <td>0.597184</td>\n",
       "      <td>0.336339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390957</td>\n",
       "      <td>0.601400</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.353685</td>\n",
       "      <td>0.178705</td>\n",
       "      <td>0.578544</td>\n",
       "      <td>0.888419</td>\n",
       "      <td>0.849101</td>\n",
       "      <td>0.853764</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329408</th>\n",
       "      <td>0.396426</td>\n",
       "      <td>0.491358</td>\n",
       "      <td>0.613357</td>\n",
       "      <td>0.315839</td>\n",
       "      <td>0.497151</td>\n",
       "      <td>0.178905</td>\n",
       "      <td>0.135769</td>\n",
       "      <td>0.213779</td>\n",
       "      <td>0.506186</td>\n",
       "      <td>0.451944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278969</td>\n",
       "      <td>0.283076</td>\n",
       "      <td>0.381482</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.328917</td>\n",
       "      <td>0.512135</td>\n",
       "      <td>0.887359</td>\n",
       "      <td>0.860323</td>\n",
       "      <td>0.857188</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329409</th>\n",
       "      <td>0.419317</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.515951</td>\n",
       "      <td>0.484980</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.309071</td>\n",
       "      <td>0.398421</td>\n",
       "      <td>0.222895</td>\n",
       "      <td>0.499825</td>\n",
       "      <td>0.462034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237801</td>\n",
       "      <td>0.524817</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.271483</td>\n",
       "      <td>0.195627</td>\n",
       "      <td>0.563810</td>\n",
       "      <td>0.881381</td>\n",
       "      <td>0.846586</td>\n",
       "      <td>0.848318</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329410</th>\n",
       "      <td>0.424651</td>\n",
       "      <td>0.532619</td>\n",
       "      <td>0.642591</td>\n",
       "      <td>0.575328</td>\n",
       "      <td>0.500163</td>\n",
       "      <td>0.077472</td>\n",
       "      <td>0.370025</td>\n",
       "      <td>0.293621</td>\n",
       "      <td>0.479370</td>\n",
       "      <td>0.230482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142101</td>\n",
       "      <td>0.409149</td>\n",
       "      <td>0.328101</td>\n",
       "      <td>0.358090</td>\n",
       "      <td>0.307833</td>\n",
       "      <td>0.550666</td>\n",
       "      <td>0.900322</td>\n",
       "      <td>0.843597</td>\n",
       "      <td>0.862650</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329411</th>\n",
       "      <td>0.287776</td>\n",
       "      <td>0.407092</td>\n",
       "      <td>0.612719</td>\n",
       "      <td>0.414715</td>\n",
       "      <td>0.459823</td>\n",
       "      <td>0.335911</td>\n",
       "      <td>0.536976</td>\n",
       "      <td>0.259037</td>\n",
       "      <td>0.551757</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>0.702591</td>\n",
       "      <td>0.228620</td>\n",
       "      <td>0.175773</td>\n",
       "      <td>0.135717</td>\n",
       "      <td>0.441221</td>\n",
       "      <td>0.889136</td>\n",
       "      <td>0.770422</td>\n",
       "      <td>0.824669</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1007_s_at  1552256_a_at  1552257_a_at  1552275_s_at  1552287_s_at  \\\n",
       "ID_REF                                                                         \n",
       "GSM329407   0.361346      0.574043      0.628138      0.472343      0.516924   \n",
       "GSM329408   0.396426      0.491358      0.613357      0.315839      0.497151   \n",
       "GSM329409   0.419317      0.538100      0.515951      0.484980      0.460500   \n",
       "GSM329410   0.424651      0.532619      0.642591      0.575328      0.500163   \n",
       "GSM329411   0.287776      0.407092      0.612719      0.414715      0.459823   \n",
       "\n",
       "           1552348_at  1552398_a_at  1552401_a_at  1552426_a_at  1552474_a_at  \\\n",
       "ID_REF                                                                          \n",
       "GSM329407    0.314686      0.581724      0.221830      0.597184      0.336339   \n",
       "GSM329408    0.178905      0.135769      0.213779      0.506186      0.451944   \n",
       "GSM329409    0.309071      0.398421      0.222895      0.499825      0.462034   \n",
       "GSM329410    0.077472      0.370025      0.293621      0.479370      0.230482   \n",
       "GSM329411    0.335911      0.536976      0.259037      0.551757      0.218830   \n",
       "\n",
       "           ...  59697_at  60471_at  65086_at  65493_at  65718_at  74694_s_at  \\\n",
       "ID_REF     ...                                                                 \n",
       "GSM329407  ...  0.390957  0.601400  0.342838  0.353685  0.178705    0.578544   \n",
       "GSM329408  ...  0.278969  0.283076  0.381482  0.360903  0.328917    0.512135   \n",
       "GSM329409  ...  0.237801  0.524817  0.375500  0.271483  0.195627    0.563810   \n",
       "GSM329410  ...  0.142101  0.409149  0.328101  0.358090  0.307833    0.550666   \n",
       "GSM329411  ...  0.475415  0.702591  0.228620  0.175773  0.135717    0.441221   \n",
       "\n",
       "           AFFX-HUMGAPDH/M33197_3_at  AFFX-HUMGAPDH/M33197_5_at  \\\n",
       "ID_REF                                                            \n",
       "GSM329407                   0.888419                   0.849101   \n",
       "GSM329408                   0.887359                   0.860323   \n",
       "GSM329409                   0.881381                   0.846586   \n",
       "GSM329410                   0.900322                   0.843597   \n",
       "GSM329411                   0.889136                   0.770422   \n",
       "\n",
       "           AFFX-HUMGAPDH/M33197_M_at             leukemia_class  \n",
       "ID_REF                                                           \n",
       "GSM329407                   0.853764  mature B-ALL with t(8;14)  \n",
       "GSM329408                   0.857188  mature B-ALL with t(8;14)  \n",
       "GSM329409                   0.848318  mature B-ALL with t(8;14)  \n",
       "GSM329410                   0.862650  mature B-ALL with t(8;14)  \n",
       "GSM329411                   0.824669  mature B-ALL with t(8;14)  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_df_chi2_5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1552256_a_at</th>\n",
       "      <th>1552280_at</th>\n",
       "      <th>1552296_at</th>\n",
       "      <th>1552348_at</th>\n",
       "      <th>1552386_at</th>\n",
       "      <th>1552388_at</th>\n",
       "      <th>1552398_a_at</th>\n",
       "      <th>1552401_a_at</th>\n",
       "      <th>1552422_at</th>\n",
       "      <th>...</th>\n",
       "      <th>50221_at</th>\n",
       "      <th>54037_at</th>\n",
       "      <th>56748_at</th>\n",
       "      <th>57588_at</th>\n",
       "      <th>58780_s_at</th>\n",
       "      <th>59631_at</th>\n",
       "      <th>59697_at</th>\n",
       "      <th>65517_at</th>\n",
       "      <th>65718_at</th>\n",
       "      <th>leukemia_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM329407</th>\n",
       "      <td>0.361346</td>\n",
       "      <td>0.574043</td>\n",
       "      <td>0.403437</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.314686</td>\n",
       "      <td>0.459216</td>\n",
       "      <td>0.104804</td>\n",
       "      <td>0.581724</td>\n",
       "      <td>0.221830</td>\n",
       "      <td>0.095132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620812</td>\n",
       "      <td>0.438114</td>\n",
       "      <td>0.184329</td>\n",
       "      <td>0.134256</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.213531</td>\n",
       "      <td>0.390957</td>\n",
       "      <td>0.148033</td>\n",
       "      <td>0.178705</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329408</th>\n",
       "      <td>0.396426</td>\n",
       "      <td>0.491358</td>\n",
       "      <td>0.246029</td>\n",
       "      <td>0.054328</td>\n",
       "      <td>0.178905</td>\n",
       "      <td>0.511325</td>\n",
       "      <td>0.152413</td>\n",
       "      <td>0.135769</td>\n",
       "      <td>0.213779</td>\n",
       "      <td>0.286709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473104</td>\n",
       "      <td>0.461370</td>\n",
       "      <td>0.115439</td>\n",
       "      <td>0.083487</td>\n",
       "      <td>0.193412</td>\n",
       "      <td>0.067892</td>\n",
       "      <td>0.278969</td>\n",
       "      <td>0.067875</td>\n",
       "      <td>0.328917</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329409</th>\n",
       "      <td>0.419317</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.212816</td>\n",
       "      <td>0.113116</td>\n",
       "      <td>0.309071</td>\n",
       "      <td>0.296136</td>\n",
       "      <td>0.151793</td>\n",
       "      <td>0.398421</td>\n",
       "      <td>0.222895</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529376</td>\n",
       "      <td>0.514960</td>\n",
       "      <td>0.175349</td>\n",
       "      <td>0.133954</td>\n",
       "      <td>0.335776</td>\n",
       "      <td>0.016975</td>\n",
       "      <td>0.237801</td>\n",
       "      <td>0.227789</td>\n",
       "      <td>0.195627</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329410</th>\n",
       "      <td>0.424651</td>\n",
       "      <td>0.532619</td>\n",
       "      <td>0.130555</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.077472</td>\n",
       "      <td>0.349910</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.370025</td>\n",
       "      <td>0.293621</td>\n",
       "      <td>0.128189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541970</td>\n",
       "      <td>0.467999</td>\n",
       "      <td>0.343024</td>\n",
       "      <td>0.140632</td>\n",
       "      <td>0.267514</td>\n",
       "      <td>0.008864</td>\n",
       "      <td>0.142101</td>\n",
       "      <td>0.048941</td>\n",
       "      <td>0.307833</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329411</th>\n",
       "      <td>0.287776</td>\n",
       "      <td>0.407092</td>\n",
       "      <td>0.282652</td>\n",
       "      <td>0.047093</td>\n",
       "      <td>0.335911</td>\n",
       "      <td>0.298619</td>\n",
       "      <td>0.304593</td>\n",
       "      <td>0.536976</td>\n",
       "      <td>0.259037</td>\n",
       "      <td>0.052542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564680</td>\n",
       "      <td>0.287897</td>\n",
       "      <td>0.194041</td>\n",
       "      <td>0.141353</td>\n",
       "      <td>0.467696</td>\n",
       "      <td>0.213617</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.135717</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1007_s_at  1552256_a_at  1552280_at  1552296_at  1552348_at  \\\n",
       "ID_REF                                                                   \n",
       "GSM329407   0.361346      0.574043    0.403437    0.248421    0.314686   \n",
       "GSM329408   0.396426      0.491358    0.246029    0.054328    0.178905   \n",
       "GSM329409   0.419317      0.538100    0.212816    0.113116    0.309071   \n",
       "GSM329410   0.424651      0.532619    0.130555    0.082809    0.077472   \n",
       "GSM329411   0.287776      0.407092    0.282652    0.047093    0.335911   \n",
       "\n",
       "           1552386_at  1552388_at  1552398_a_at  1552401_a_at  1552422_at  \\\n",
       "ID_REF                                                                      \n",
       "GSM329407    0.459216    0.104804      0.581724      0.221830    0.095132   \n",
       "GSM329408    0.511325    0.152413      0.135769      0.213779    0.286709   \n",
       "GSM329409    0.296136    0.151793      0.398421      0.222895    0.036946   \n",
       "GSM329410    0.349910    0.070955      0.370025      0.293621    0.128189   \n",
       "GSM329411    0.298619    0.304593      0.536976      0.259037    0.052542   \n",
       "\n",
       "           ...  50221_at  54037_at  56748_at  57588_at  58780_s_at  59631_at  \\\n",
       "ID_REF     ...                                                                 \n",
       "GSM329407  ...  0.620812  0.438114  0.184329  0.134256    0.350074  0.213531   \n",
       "GSM329408  ...  0.473104  0.461370  0.115439  0.083487    0.193412  0.067892   \n",
       "GSM329409  ...  0.529376  0.514960  0.175349  0.133954    0.335776  0.016975   \n",
       "GSM329410  ...  0.541970  0.467999  0.343024  0.140632    0.267514  0.008864   \n",
       "GSM329411  ...  0.564680  0.287897  0.194041  0.141353    0.467696  0.213617   \n",
       "\n",
       "           59697_at  65517_at  65718_at             leukemia_class  \n",
       "ID_REF                                                              \n",
       "GSM329407  0.390957  0.148033  0.178705  mature B-ALL with t(8;14)  \n",
       "GSM329408  0.278969  0.067875  0.328917  mature B-ALL with t(8;14)  \n",
       "GSM329409  0.237801  0.227789  0.195627  mature B-ALL with t(8;14)  \n",
       "GSM329410  0.142101  0.048941  0.307833  mature B-ALL with t(8;14)  \n",
       "GSM329411  0.475415  0.175493  0.135717  mature B-ALL with t(8;14)  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_df_fc_5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1552256_a_at</th>\n",
       "      <th>1552257_a_at</th>\n",
       "      <th>1552275_s_at</th>\n",
       "      <th>1552287_s_at</th>\n",
       "      <th>1552296_at</th>\n",
       "      <th>1552302_at</th>\n",
       "      <th>1552348_at</th>\n",
       "      <th>1552398_a_at</th>\n",
       "      <th>1552401_a_at</th>\n",
       "      <th>...</th>\n",
       "      <th>58780_s_at</th>\n",
       "      <th>59697_at</th>\n",
       "      <th>60471_at</th>\n",
       "      <th>65086_at</th>\n",
       "      <th>65493_at</th>\n",
       "      <th>74694_s_at</th>\n",
       "      <th>AFFX-HUMGAPDH/M33197_3_at</th>\n",
       "      <th>AFFX-HUMGAPDH/M33197_5_at</th>\n",
       "      <th>AFFX-HUMGAPDH/M33197_M_at</th>\n",
       "      <th>leukemia_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM329407</th>\n",
       "      <td>0.361346</td>\n",
       "      <td>0.574043</td>\n",
       "      <td>0.628138</td>\n",
       "      <td>0.472343</td>\n",
       "      <td>0.516924</td>\n",
       "      <td>0.248421</td>\n",
       "      <td>0.241912</td>\n",
       "      <td>0.314686</td>\n",
       "      <td>0.581724</td>\n",
       "      <td>0.221830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.390957</td>\n",
       "      <td>0.601400</td>\n",
       "      <td>0.342838</td>\n",
       "      <td>0.353685</td>\n",
       "      <td>0.578544</td>\n",
       "      <td>0.888419</td>\n",
       "      <td>0.849101</td>\n",
       "      <td>0.853764</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329408</th>\n",
       "      <td>0.396426</td>\n",
       "      <td>0.491358</td>\n",
       "      <td>0.613357</td>\n",
       "      <td>0.315839</td>\n",
       "      <td>0.497151</td>\n",
       "      <td>0.054328</td>\n",
       "      <td>0.292557</td>\n",
       "      <td>0.178905</td>\n",
       "      <td>0.135769</td>\n",
       "      <td>0.213779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193412</td>\n",
       "      <td>0.278969</td>\n",
       "      <td>0.283076</td>\n",
       "      <td>0.381482</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.512135</td>\n",
       "      <td>0.887359</td>\n",
       "      <td>0.860323</td>\n",
       "      <td>0.857188</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329409</th>\n",
       "      <td>0.419317</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.515951</td>\n",
       "      <td>0.484980</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.113116</td>\n",
       "      <td>0.225458</td>\n",
       "      <td>0.309071</td>\n",
       "      <td>0.398421</td>\n",
       "      <td>0.222895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335776</td>\n",
       "      <td>0.237801</td>\n",
       "      <td>0.524817</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.271483</td>\n",
       "      <td>0.563810</td>\n",
       "      <td>0.881381</td>\n",
       "      <td>0.846586</td>\n",
       "      <td>0.848318</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329410</th>\n",
       "      <td>0.424651</td>\n",
       "      <td>0.532619</td>\n",
       "      <td>0.642591</td>\n",
       "      <td>0.575328</td>\n",
       "      <td>0.500163</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.133297</td>\n",
       "      <td>0.077472</td>\n",
       "      <td>0.370025</td>\n",
       "      <td>0.293621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267514</td>\n",
       "      <td>0.142101</td>\n",
       "      <td>0.409149</td>\n",
       "      <td>0.328101</td>\n",
       "      <td>0.358090</td>\n",
       "      <td>0.550666</td>\n",
       "      <td>0.900322</td>\n",
       "      <td>0.843597</td>\n",
       "      <td>0.862650</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329411</th>\n",
       "      <td>0.287776</td>\n",
       "      <td>0.407092</td>\n",
       "      <td>0.612719</td>\n",
       "      <td>0.414715</td>\n",
       "      <td>0.459823</td>\n",
       "      <td>0.047093</td>\n",
       "      <td>0.118265</td>\n",
       "      <td>0.335911</td>\n",
       "      <td>0.536976</td>\n",
       "      <td>0.259037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467696</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>0.702591</td>\n",
       "      <td>0.228620</td>\n",
       "      <td>0.175773</td>\n",
       "      <td>0.441221</td>\n",
       "      <td>0.889136</td>\n",
       "      <td>0.770422</td>\n",
       "      <td>0.824669</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1007_s_at  1552256_a_at  1552257_a_at  1552275_s_at  1552287_s_at  \\\n",
       "ID_REF                                                                         \n",
       "GSM329407   0.361346      0.574043      0.628138      0.472343      0.516924   \n",
       "GSM329408   0.396426      0.491358      0.613357      0.315839      0.497151   \n",
       "GSM329409   0.419317      0.538100      0.515951      0.484980      0.460500   \n",
       "GSM329410   0.424651      0.532619      0.642591      0.575328      0.500163   \n",
       "GSM329411   0.287776      0.407092      0.612719      0.414715      0.459823   \n",
       "\n",
       "           1552296_at  1552302_at  1552348_at  1552398_a_at  1552401_a_at  \\\n",
       "ID_REF                                                                      \n",
       "GSM329407    0.248421    0.241912    0.314686      0.581724      0.221830   \n",
       "GSM329408    0.054328    0.292557    0.178905      0.135769      0.213779   \n",
       "GSM329409    0.113116    0.225458    0.309071      0.398421      0.222895   \n",
       "GSM329410    0.082809    0.133297    0.077472      0.370025      0.293621   \n",
       "GSM329411    0.047093    0.118265    0.335911      0.536976      0.259037   \n",
       "\n",
       "           ...  58780_s_at  59697_at  60471_at  65086_at  65493_at  \\\n",
       "ID_REF     ...                                                       \n",
       "GSM329407  ...    0.350074  0.390957  0.601400  0.342838  0.353685   \n",
       "GSM329408  ...    0.193412  0.278969  0.283076  0.381482  0.360903   \n",
       "GSM329409  ...    0.335776  0.237801  0.524817  0.375500  0.271483   \n",
       "GSM329410  ...    0.267514  0.142101  0.409149  0.328101  0.358090   \n",
       "GSM329411  ...    0.467696  0.475415  0.702591  0.228620  0.175773   \n",
       "\n",
       "           74694_s_at  AFFX-HUMGAPDH/M33197_3_at  AFFX-HUMGAPDH/M33197_5_at  \\\n",
       "ID_REF                                                                        \n",
       "GSM329407    0.578544                   0.888419                   0.849101   \n",
       "GSM329408    0.512135                   0.887359                   0.860323   \n",
       "GSM329409    0.563810                   0.881381                   0.846586   \n",
       "GSM329410    0.550666                   0.900322                   0.843597   \n",
       "GSM329411    0.441221                   0.889136                   0.770422   \n",
       "\n",
       "           AFFX-HUMGAPDH/M33197_M_at             leukemia_class  \n",
       "ID_REF                                                           \n",
       "GSM329407                   0.853764  mature B-ALL with t(8;14)  \n",
       "GSM329408                   0.857188  mature B-ALL with t(8;14)  \n",
       "GSM329409                   0.848318  mature B-ALL with t(8;14)  \n",
       "GSM329410                   0.862650  mature B-ALL with t(8;14)  \n",
       "GSM329411                   0.824669  mature B-ALL with t(8;14)  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explorez rapidement les 3 DataFrames pour bien comprendre les données. \n",
    "print('features_df_mutual_5000')\n",
    "display(features_df_mutual_5000.head())\n",
    "print('features_df_chi2_5000')\n",
    "display(features_df_chi2_5000.head())\n",
    "print('features_df_fc_5000')\n",
    "display(features_df_fc_5000.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8f82ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names (features names / noms d'attributs)\n",
    "cols_mutual = list(features_df_mutual_5000.columns)\n",
    "cols_chi2 = list(features_df_chi2_5000.columns)\n",
    "cols_fc = list(features_df_fc_5000.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0b3e4",
   "metadata": {},
   "source": [
    "### Total features union\n",
    "\n",
    "Si l'on prend la totalité des variables choisies par nos trois méthodes, nous obtenons 7615 variables différentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "987d5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7614\n"
     ]
    }
   ],
   "source": [
    "# Total features union\n",
    "all_features_union = set(cols_mutual + cols_chi2 + cols_fc)\n",
    "print(len(all_features_union))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3759f7",
   "metadata": {},
   "source": [
    "### Total features intersection\n",
    "\n",
    "Si l'on choisi de prendre uniquement les variables sélectionnées par nos trois méthodes, nous obtenons 2458 variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d60daecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459\n"
     ]
    }
   ],
   "source": [
    "# Total features intersection\n",
    "all_features_intersect = set(cols_mutual).intersection(cols_chi2).intersection(cols_fc)\n",
    "print(len(all_features_intersect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e7b4b",
   "metadata": {},
   "source": [
    "### Total features union of intersections\n",
    "\n",
    "Nous pouvons choisir les variables qui ont été retenues par au moins deux méthodes en prenant l'union des intersections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7556bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection between mutual and chi2: 2575\n",
      "Intersection between mutual and fc: 4413\n",
      "Intersection between fc and chi2: 2860\n",
      "Intersection between mutual, fc and chi2: 2459\n",
      "-------------------\n",
      "Union of intersections 4930\n"
     ]
    }
   ],
   "source": [
    "# Total features union of intersections\n",
    "\n",
    "# Intersection between the 5000 columns of mutual_information and the 5000 of chi2\n",
    "features_mutual_n_chi2 = set(cols_mutual).intersection(cols_chi2)\n",
    "l_mutual_chi2 = len(features_mutual_n_chi2)\n",
    "print(f\"Intersection between mutual and chi2: {l_mutual_chi2}\")\n",
    "\n",
    "# Same with mutual_information and f_classifier\n",
    "features_mutual_n_fc = set(cols_mutual).intersection(cols_fc)\n",
    "l_mutual_fc = len(features_mutual_n_fc)\n",
    "print(f\"Intersection between mutual and fc: {l_mutual_fc}\")\n",
    "\n",
    "# Same with f_classifier and chi2\n",
    "features_fc_n_chi2 = set(cols_fc).intersection(cols_chi2)\n",
    "l_fc_chi2 = len(features_fc_n_chi2)\n",
    "print(f\"Intersection between fc and chi2: {l_fc_chi2}\")\n",
    "\n",
    "# Intersection between the three (length)\n",
    "l_fc_chi2_mutual = len(set(cols_fc).intersection(cols_chi2).intersection(cols_mutual))\n",
    "print(f\"Intersection between mutual, fc and chi2: {l_fc_chi2_mutual}\")\n",
    "\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "# Creating a set removes the duplicates (intersection between the three are present multiple times until now)\n",
    "all_features_union_of_intersect = list(set(list(features_mutual_n_chi2) + \n",
    "                                           list(features_mutual_n_fc) + \n",
    "                                           list(features_fc_n_chi2)))\n",
    "\n",
    "print(f\"Union of intersections {len(all_features_union_of_intersect)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f020e1",
   "metadata": {},
   "source": [
    "Voici un petit diagramme de Venn pour vous aider à visualiser les features en commun entre les différentes méthodes (calculs fait à la main à partir des intersections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5eb69d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the library\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    " \n",
    "v=venn3(subsets = (472, 2024, 116, 186,1954,402,2458), set_labels = ('Mutual information', 'Chi2', 'f classifier'))\n",
    "#v.get_label_by_id('A').set_text('My Favourite group!')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1651c",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- Décrivez le dataset MILE et son contenu. D'où vient-il et quel est son but ? Que représentent les données ? Donnez des informations sur les variables indépendantes, sur la variable dépendante, la tâche de machine learning à effectuer etc. \n",
    "- Donnez une description des trois méthodes utilisées pour le premier filtre\n",
    "- Pourquoi utiliser des méthodes simples commes celles-ci pour une première étape de filtre ?\n",
    "- Nous choisissons de garder l'union des intersections des features (création du DF ci-dessous). D'après vous, pourquoi faire ce choix plutôt que de garder la totalité des features sélectionnées par les trois méthodes (union) ou les features en commun entre les trois méthodes (intersection) ?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb1ca4",
   "metadata": {},
   "source": [
    "Réponses:\n",
    "\n",
    "Le dataset MILE (Microarray Innovations in LEukemia) a été utilisé dans une étude pour diagnostiquer la leucémie en fonction d'expressions de gènes. Ce dataset contient 2096 échantillons de sang ou de moelle épinière de patients de leucémie chronique. Chaque variable à l'exception de la classe de leucémie (`leukemia_class`) est l'expression du gène qui a le même nom que le champ.\n",
    "\n",
    "Mutual information : L'information mutuelle entre deux variables aléatoires est une valeur non négative qui mesure la dépendance entre les variables. Elle est égale à zéro si et seulement si deux variables aléatoires sont indépendantes, et des valeurs plus élevées signifient une plus grande dépendance. La fonction s'appuie sur des méthodes non paramétriques basées sur l'estimation de l'entropie à partir des distances entre les k-voisins les plus proches.\n",
    "\n",
    "Chi Squared (chi2) : Ce score peut être utilisé pour sélectionner les caractéristiques `n_features` présentant les valeurs les plus élevées pour la statistique chi-carré de test à partir de X, qui ne doit contenir que des valeurs entières non négatives de caractéristiques telles que des booléens ou des fréquences (par exemple, le nombre de termes dans la classification de documents), par rapport aux classes.\n",
    "\n",
    "F Classifier : Cette méthode calcule la valeur F de l'ANOVA pour l'échantillon fourni. La valeur F de l'ANOVA correspond à la valeur du test F qu'on effectue sur nos données après l'analyse des variances (ANOVA). On doit choisir le nombre N d'attributs qu'on veut garder.\n",
    "\n",
    "On utilise ces méthodes pour déjà avoir moins d'attributs pour qu'on juge comme étant *relevant* pour que la sélection d'atrributs avec les *wrappers* prenne moins de temps de calcul. On suppose que ces méthodes jugées comme étant simples sont bien pour la première étape parce qu'on veut surtout réduire la dimensionalité.\n",
    "\n",
    "On a fait ce choix car comme ça on est sûr que les attributs ont été jugées *relevant* par plusieurs méthodes. \n",
    "\n",
    "Garder l'union des 3 méthodes n'est pas une bonne idée car on risquerait de prendre des attributs qui ne sont pas vraiment utiles, même si une des 3 méthodes les considère comme tel. \n",
    "\n",
    "Le choix de l'intersection n'est pas bon car on limite un peu trop nos attributs, si on a des attributs que 2 des 3 méthodes considèrent comme utiles, on ne va pas les prendre à cause de la dernière méthode qui ne les considère pas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08509d1c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24606a36",
   "metadata": {},
   "source": [
    "On crée notre DataFrame *df_union_intersect* qui va être utilisé pour la suite du TP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0653ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2897/750371106.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_union_intersect[\"leukemia_class\"] = leukemia_class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>230424_at</th>\n",
       "      <th>230768_at</th>\n",
       "      <th>202382_s_at</th>\n",
       "      <th>218729_at</th>\n",
       "      <th>203232_s_at</th>\n",
       "      <th>219890_at</th>\n",
       "      <th>206116_s_at</th>\n",
       "      <th>229507_at</th>\n",
       "      <th>210942_s_at</th>\n",
       "      <th>222307_at</th>\n",
       "      <th>...</th>\n",
       "      <th>237460_x_at</th>\n",
       "      <th>221782_at</th>\n",
       "      <th>1556599_s_at</th>\n",
       "      <th>235780_at</th>\n",
       "      <th>209406_at</th>\n",
       "      <th>1557452_at</th>\n",
       "      <th>228570_at</th>\n",
       "      <th>210638_s_at</th>\n",
       "      <th>1560081_at</th>\n",
       "      <th>leukemia_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM329407</th>\n",
       "      <td>0.331268</td>\n",
       "      <td>0.306986</td>\n",
       "      <td>0.546137</td>\n",
       "      <td>0.475635</td>\n",
       "      <td>0.508969</td>\n",
       "      <td>0.254712</td>\n",
       "      <td>0.276661</td>\n",
       "      <td>0.391140</td>\n",
       "      <td>0.291109</td>\n",
       "      <td>0.343671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254989</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.354555</td>\n",
       "      <td>0.455670</td>\n",
       "      <td>0.277111</td>\n",
       "      <td>0.335972</td>\n",
       "      <td>0.678661</td>\n",
       "      <td>0.384211</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329408</th>\n",
       "      <td>0.450948</td>\n",
       "      <td>0.323163</td>\n",
       "      <td>0.293921</td>\n",
       "      <td>0.361606</td>\n",
       "      <td>0.178374</td>\n",
       "      <td>0.106468</td>\n",
       "      <td>0.324446</td>\n",
       "      <td>0.346070</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.303945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196411</td>\n",
       "      <td>0.486495</td>\n",
       "      <td>0.528467</td>\n",
       "      <td>0.423193</td>\n",
       "      <td>0.497250</td>\n",
       "      <td>0.373922</td>\n",
       "      <td>0.257741</td>\n",
       "      <td>0.660882</td>\n",
       "      <td>0.308165</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329409</th>\n",
       "      <td>0.318763</td>\n",
       "      <td>0.403481</td>\n",
       "      <td>0.369027</td>\n",
       "      <td>0.314639</td>\n",
       "      <td>0.269337</td>\n",
       "      <td>0.398724</td>\n",
       "      <td>0.377411</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.057850</td>\n",
       "      <td>0.437838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>0.526856</td>\n",
       "      <td>0.208854</td>\n",
       "      <td>0.502243</td>\n",
       "      <td>0.439005</td>\n",
       "      <td>0.362559</td>\n",
       "      <td>0.229354</td>\n",
       "      <td>0.675383</td>\n",
       "      <td>0.423689</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329410</th>\n",
       "      <td>0.361033</td>\n",
       "      <td>0.192589</td>\n",
       "      <td>0.527010</td>\n",
       "      <td>0.396369</td>\n",
       "      <td>0.321070</td>\n",
       "      <td>0.122636</td>\n",
       "      <td>0.155031</td>\n",
       "      <td>0.373303</td>\n",
       "      <td>0.154414</td>\n",
       "      <td>0.468694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175936</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.315897</td>\n",
       "      <td>0.470738</td>\n",
       "      <td>0.554640</td>\n",
       "      <td>0.370452</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.612337</td>\n",
       "      <td>0.154018</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM329411</th>\n",
       "      <td>0.294387</td>\n",
       "      <td>0.103624</td>\n",
       "      <td>0.302551</td>\n",
       "      <td>0.551392</td>\n",
       "      <td>0.372645</td>\n",
       "      <td>0.546969</td>\n",
       "      <td>0.403817</td>\n",
       "      <td>0.237433</td>\n",
       "      <td>0.312112</td>\n",
       "      <td>0.530691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394285</td>\n",
       "      <td>0.425787</td>\n",
       "      <td>0.258531</td>\n",
       "      <td>0.485888</td>\n",
       "      <td>0.096170</td>\n",
       "      <td>0.347922</td>\n",
       "      <td>0.468605</td>\n",
       "      <td>0.766922</td>\n",
       "      <td>0.425164</td>\n",
       "      <td>mature B-ALL with t(8;14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM331728</th>\n",
       "      <td>0.241402</td>\n",
       "      <td>0.243356</td>\n",
       "      <td>0.458162</td>\n",
       "      <td>0.611733</td>\n",
       "      <td>0.439574</td>\n",
       "      <td>0.657115</td>\n",
       "      <td>0.461266</td>\n",
       "      <td>0.324839</td>\n",
       "      <td>0.444375</td>\n",
       "      <td>0.429124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238627</td>\n",
       "      <td>0.393475</td>\n",
       "      <td>0.204550</td>\n",
       "      <td>0.442925</td>\n",
       "      <td>0.412610</td>\n",
       "      <td>0.329338</td>\n",
       "      <td>0.341373</td>\n",
       "      <td>0.782171</td>\n",
       "      <td>0.294165</td>\n",
       "      <td>Non-leukemia and healthy bone marrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM331729</th>\n",
       "      <td>0.286244</td>\n",
       "      <td>0.256870</td>\n",
       "      <td>0.443485</td>\n",
       "      <td>0.612496</td>\n",
       "      <td>0.470756</td>\n",
       "      <td>0.644453</td>\n",
       "      <td>0.488208</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>0.454338</td>\n",
       "      <td>0.425475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046350</td>\n",
       "      <td>0.392964</td>\n",
       "      <td>0.308635</td>\n",
       "      <td>0.446529</td>\n",
       "      <td>0.416076</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.367622</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.339199</td>\n",
       "      <td>Non-leukemia and healthy bone marrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM331730</th>\n",
       "      <td>0.308497</td>\n",
       "      <td>0.314512</td>\n",
       "      <td>0.506532</td>\n",
       "      <td>0.830107</td>\n",
       "      <td>0.499705</td>\n",
       "      <td>0.615640</td>\n",
       "      <td>0.581173</td>\n",
       "      <td>0.332442</td>\n",
       "      <td>0.405370</td>\n",
       "      <td>0.375568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241842</td>\n",
       "      <td>0.377044</td>\n",
       "      <td>0.110269</td>\n",
       "      <td>0.385209</td>\n",
       "      <td>0.435148</td>\n",
       "      <td>0.234115</td>\n",
       "      <td>0.371560</td>\n",
       "      <td>0.762706</td>\n",
       "      <td>0.277079</td>\n",
       "      <td>Non-leukemia and healthy bone marrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM331731</th>\n",
       "      <td>0.184960</td>\n",
       "      <td>0.143964</td>\n",
       "      <td>0.480632</td>\n",
       "      <td>0.598580</td>\n",
       "      <td>0.428810</td>\n",
       "      <td>0.668153</td>\n",
       "      <td>0.536131</td>\n",
       "      <td>0.268356</td>\n",
       "      <td>0.409832</td>\n",
       "      <td>0.392285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033142</td>\n",
       "      <td>0.448998</td>\n",
       "      <td>0.071986</td>\n",
       "      <td>0.382954</td>\n",
       "      <td>0.433054</td>\n",
       "      <td>0.239693</td>\n",
       "      <td>0.406974</td>\n",
       "      <td>0.792523</td>\n",
       "      <td>0.327274</td>\n",
       "      <td>Non-leukemia and healthy bone marrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM331732</th>\n",
       "      <td>0.218176</td>\n",
       "      <td>0.230472</td>\n",
       "      <td>0.507656</td>\n",
       "      <td>0.582886</td>\n",
       "      <td>0.552267</td>\n",
       "      <td>0.706209</td>\n",
       "      <td>0.446379</td>\n",
       "      <td>0.326257</td>\n",
       "      <td>0.423782</td>\n",
       "      <td>0.468677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.434988</td>\n",
       "      <td>0.241282</td>\n",
       "      <td>0.471008</td>\n",
       "      <td>0.389340</td>\n",
       "      <td>0.324767</td>\n",
       "      <td>0.404783</td>\n",
       "      <td>0.773315</td>\n",
       "      <td>0.363134</td>\n",
       "      <td>Non-leukemia and healthy bone marrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2096 rows × 4930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           230424_at  230768_at  202382_s_at  218729_at  203232_s_at  \\\n",
       "ID_REF                                                                 \n",
       "GSM329407   0.331268   0.306986     0.546137   0.475635     0.508969   \n",
       "GSM329408   0.450948   0.323163     0.293921   0.361606     0.178374   \n",
       "GSM329409   0.318763   0.403481     0.369027   0.314639     0.269337   \n",
       "GSM329410   0.361033   0.192589     0.527010   0.396369     0.321070   \n",
       "GSM329411   0.294387   0.103624     0.302551   0.551392     0.372645   \n",
       "...              ...        ...          ...        ...          ...   \n",
       "GSM331728   0.241402   0.243356     0.458162   0.611733     0.439574   \n",
       "GSM331729   0.286244   0.256870     0.443485   0.612496     0.470756   \n",
       "GSM331730   0.308497   0.314512     0.506532   0.830107     0.499705   \n",
       "GSM331731   0.184960   0.143964     0.480632   0.598580     0.428810   \n",
       "GSM331732   0.218176   0.230472     0.507656   0.582886     0.552267   \n",
       "\n",
       "           219890_at  206116_s_at  229507_at  210942_s_at  222307_at  ...  \\\n",
       "ID_REF                                                                ...   \n",
       "GSM329407   0.254712     0.276661   0.391140     0.291109   0.343671  ...   \n",
       "GSM329408   0.106468     0.324446   0.346070     0.017561   0.303945  ...   \n",
       "GSM329409   0.398724     0.377411   0.341919     0.057850   0.437838  ...   \n",
       "GSM329410   0.122636     0.155031   0.373303     0.154414   0.468694  ...   \n",
       "GSM329411   0.546969     0.403817   0.237433     0.312112   0.530691  ...   \n",
       "...              ...          ...        ...          ...        ...  ...   \n",
       "GSM331728   0.657115     0.461266   0.324839     0.444375   0.429124  ...   \n",
       "GSM331729   0.644453     0.488208   0.261068     0.454338   0.425475  ...   \n",
       "GSM331730   0.615640     0.581173   0.332442     0.405370   0.375568  ...   \n",
       "GSM331731   0.668153     0.536131   0.268356     0.409832   0.392285  ...   \n",
       "GSM331732   0.706209     0.446379   0.326257     0.423782   0.468677  ...   \n",
       "\n",
       "           237460_x_at  221782_at  1556599_s_at  235780_at  209406_at  \\\n",
       "ID_REF                                                                  \n",
       "GSM329407     0.254989   0.502806      0.246377   0.354555   0.455670   \n",
       "GSM329408     0.196411   0.486495      0.528467   0.423193   0.497250   \n",
       "GSM329409     0.258407   0.526856      0.208854   0.502243   0.439005   \n",
       "GSM329410     0.175936   0.458179      0.315897   0.470738   0.554640   \n",
       "GSM329411     0.394285   0.425787      0.258531   0.485888   0.096170   \n",
       "...                ...        ...           ...        ...        ...   \n",
       "GSM331728     0.238627   0.393475      0.204550   0.442925   0.412610   \n",
       "GSM331729     0.046350   0.392964      0.308635   0.446529   0.416076   \n",
       "GSM331730     0.241842   0.377044      0.110269   0.385209   0.435148   \n",
       "GSM331731     0.033142   0.448998      0.071986   0.382954   0.433054   \n",
       "GSM331732     0.192450   0.434988      0.241282   0.471008   0.389340   \n",
       "\n",
       "           1557452_at  228570_at  210638_s_at  1560081_at  \\\n",
       "ID_REF                                                      \n",
       "GSM329407    0.277111   0.335972     0.678661    0.384211   \n",
       "GSM329408    0.373922   0.257741     0.660882    0.308165   \n",
       "GSM329409    0.362559   0.229354     0.675383    0.423689   \n",
       "GSM329410    0.370452   0.063168     0.612337    0.154018   \n",
       "GSM329411    0.347922   0.468605     0.766922    0.425164   \n",
       "...               ...        ...          ...         ...   \n",
       "GSM331728    0.329338   0.341373     0.782171    0.294165   \n",
       "GSM331729    0.231100   0.367622     0.787879    0.339199   \n",
       "GSM331730    0.234115   0.371560     0.762706    0.277079   \n",
       "GSM331731    0.239693   0.406974     0.792523    0.327274   \n",
       "GSM331732    0.324767   0.404783     0.773315    0.363134   \n",
       "\n",
       "                                 leukemia_class  \n",
       "ID_REF                                           \n",
       "GSM329407             mature B-ALL with t(8;14)  \n",
       "GSM329408             mature B-ALL with t(8;14)  \n",
       "GSM329409             mature B-ALL with t(8;14)  \n",
       "GSM329410             mature B-ALL with t(8;14)  \n",
       "GSM329411             mature B-ALL with t(8;14)  \n",
       "...                                         ...  \n",
       "GSM331728  Non-leukemia and healthy bone marrow  \n",
       "GSM331729  Non-leukemia and healthy bone marrow  \n",
       "GSM331730  Non-leukemia and healthy bone marrow  \n",
       "GSM331731  Non-leukemia and healthy bone marrow  \n",
       "GSM331732  Non-leukemia and healthy bone marrow  \n",
       "\n",
       "[2096 rows x 4930 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the column lists from each method\n",
    "mutual_columns = features_df_mutual_5000.columns.tolist()\n",
    "chi2_unique = [col for col in features_df_chi2_5000.columns if col not in mutual_columns]\n",
    "fc_unique   = [col for col in features_df_fc_5000.columns if col not in (mutual_columns + chi2_unique)]\n",
    "\n",
    "# Concatenate the selected columns to form the union DataFrame\n",
    "df_union = pd.concat([\n",
    "    features_df_mutual_5000[mutual_columns],\n",
    "    features_df_chi2_5000[chi2_unique],\n",
    "    features_df_fc_5000[fc_unique]\n",
    "], axis=1)\n",
    "\n",
    "# Retain only the features selected by at least two methods (union of intersections)\n",
    "df_union_intersect = df_union.loc[:, all_features_union_of_intersect]\n",
    "\n",
    "# Retain only the features selected by all three methods (intersection)\n",
    "df_intersect = df_union.loc[:, list(all_features_intersect)]\n",
    "\n",
    "# Move 'leukemia_class' to the last column\n",
    "leukemia_class = df_union_intersect.pop(\"leukemia_class\")\n",
    "df_union_intersect[\"leukemia_class\"] = leukemia_class\n",
    "\n",
    "df_union_intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e48cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1411063",
   "metadata": {},
   "source": [
    "## 2) Wrapper methods\n",
    "\n",
    "\n",
    "Nous allons maintenant utiliser deux *wrapper methods* afin de réduire notre sélection d'environ 5'000 attributs à environ 500 (ordre de grandeur). Pour cela nous allons utiliser la Recurisve Features Elimination (RFE) de scikit-learn avec Random Forest et Support Vector Machine. \n",
    "\n",
    "(*Note: sans Cross Validation (rfecv) car très demandant en ressources*)\n",
    "\n",
    "\n",
    "- Répondez aux questions \n",
    "- RFE-RF: Exécutez le code donné et répondez aux questions\n",
    "- RFE-SVM: Complétez le code demandé et répondez aux questions\n",
    "- Sélectionnez les features que vous garderez pour la prochaine étape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a19235",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "- Écrivez une courte description de ce que sont les méthodes \"wrapper\" pour la sélection d'attributs. Comment fonctionne RFE (implémentation de sklearn) \n",
    "- Pourquoi est-il possible de l'utiliser avec Random Forest et Support Vector Machine (SVM) ?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3609813",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n",
    "Les \"wrapper\" sont une méthode qui consiste à utiliser un algorithme d'apprentissage pour trouver les attributs. \n",
    "\n",
    "RFE fait un *ranking* des attributs avec l'élimination récursive d'attrbuts. Le but de cette méthode est de choisir des attributs récursivement en considérant des sous-ensembles d'attributs de plus en plus petits. L'estimateur est entraîné sur l'ensemble initial d'attributs et l'importance de chaque attribut est obtenue par le biais d'un attribut spécifique ou d'une variable d'appel. Ensuite, les attributs les moins importantes sont éliminées de l'ensemble actuel d'attributs. Cette procédure est répétée de manière récursive sur l'ensemble élagué jusqu'à ce que le nombre souhaité d'attributs soit atteint.\n",
    "\n",
    "On peut l'utiliser avec Random Forest et SVM car ces deux méthodes identifient bien l'importance des attributs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f5a2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffea96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données \n",
    "\n",
    "X_uoi, y_uoi = df_union_intersect.drop(columns=\"leukemia_class\"), df_union_intersect[\"leukemia_class\"]\n",
    "\n",
    "X_i, y_i = df_intersect.drop(columns=\"leukemia_class\"), df_intersect[\"leukemia_class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ad0e7",
   "metadata": {},
   "source": [
    "### RFE-RF\n",
    "\n",
    "Exécuter le code donné ci-dessous. Complétez les commentaires (les # sans rien) dans le code afin d'expliquer ce qui est fait puis répondez aux questions.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Attention:</b> Temps d'exécution avec les paramètres actuels: RFE-RF (50 sec) / RFE-SVM (5 minutes avec LinearSVC, 30 secondes avec SVC)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "155fb261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.09711456298828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "#---------------\n",
    "\n",
    "# RFE avec un classifieur Random Forest avec 25 estimateurs, une profondeur maximale de 10, on veut 500 attributs\n",
    "selector = RFE(estimator=RandomForestClassifier(random_state=0, \n",
    "                                                n_estimators=25, \n",
    "                                                max_depth=10), \n",
    "               n_features_to_select=500, \n",
    "               step=0.02)\n",
    "\n",
    "# On effectue la sélection d'attributs sur les données\n",
    "selector = selector.fit(X_uoi, y_uoi)\n",
    "\n",
    "# Liste des attributs sélectionnées\n",
    "features_names_RFERF = X_uoi.columns[selector.support_]\n",
    "\n",
    "#---------------\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# without step: 1581 sec\n",
    "# with step: 49 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06338fc9",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "On cherche à retirer les variables qui sont les plus mauvais prédicteurs. Quelle influence cela a-t-il sur le choix des paramètres de notre RandomForestClassifier ? En d'autres termes: Que changeriez-vous si vous utilisiez Random Forest pour créer un modèle performant au lieu de l'utiliser pour éliminer les plus mauvaises features ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5b2f5",
   "metadata": {},
   "source": [
    "*Réponse*\n",
    "\n",
    "Le nombre d'estimateurs et la profondeur maximale sont les paramètres à changer si on voulait faire un modèle performant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919885a4",
   "metadata": {},
   "source": [
    "---\n",
    "### RFE-SVM\n",
    "\n",
    "En vous basant sur le code de RFE-RF ci-dessus, écrivez le code pour une RFE avec cette fois-ci l'estimateur SVM. \n",
    "\n",
    "Utilisez les paramètres suivant:\n",
    "- Pour RFE: \n",
    "    - estimator = SVC\n",
    "    - N_features: 500\n",
    "    - step=0.05\n",
    "\n",
    "\n",
    "- Pour SVC\n",
    "    - Kernel = 'linear'\n",
    "    - C=1\n",
    "    - max_iter=1000\n",
    "\n",
    "Gardez les noms des 500 features choisies dans une variable nommée *features_names_RFESVM*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "selector_svm = RFE(estimator=SVC(kernel='linear', C=1, max_iter=1000), \n",
    "               n_features_to_select=500, \n",
    "               step=0.05)\n",
    "\n",
    "selector_svm = selector_svm.fit(X_uoi, y_uoi)\n",
    "\n",
    "# Liste des attributs sélectionnées\n",
    "features_names_RFESVM = X_uoi.columns[selector_svm.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedefbd9",
   "metadata": {},
   "source": [
    "### Features retenues par les deux méthodes\n",
    "\n",
    "Créez une liste nommée \"**features_names_wrapper**\" avec l'**union** des features retenues. Vous devriez obtenir environ 8-900 features en tout. Affichez vos résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a817f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['202382_s_at', '206116_s_at', '213096_at', '229610_at', '211211_x_at',\n",
       "       '1552634_a_at', '211126_s_at', '226635_at', '243000_at', '223120_at',\n",
       "       ...\n",
       "       '201664_at', '244876_at', '221773_at', '204060_s_at', '224791_at',\n",
       "       '200832_s_at', '229967_at', '220588_at', '1556599_s_at', '228570_at'],\n",
       "      dtype='object', length=500)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union des features de features_names_RFESVM et features_names_RFERF\n",
    "\n",
    "features_names_wrapper = features_names_RFERF.copy()\n",
    "features_names_wrapper.union(features_names_RFESVM)\n",
    "\n",
    "print(len(features_names_wrapper))\n",
    "\n",
    "features_names_wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349168d",
   "metadata": {},
   "source": [
    "### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2917d68",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Pourquoi garder les ~8-900 features issues de l'union et pas uniquement les ~100 de l'intersection ?\n",
    "- Dans un contexte plus réél avec du temps et des ressources en quantité, comment auriez-vous amélioré l'utilisation de RFE pour faire une sélection encore plus pértinente de variables ?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d844a3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3feef",
   "metadata": {},
   "source": [
    "*Réponse:* on garde l'union pour ne pas \"louper\" des attributs qui ont été trouvées par une méthode mais pas l'autre. On a 500 features, ce qui nous paraît un peu bizarre car cela signifie que nos deux méthodes ont trouvé exactement la même chose.\n",
    "\n",
    "On aurait pu utiliser RFECV pour faire de la cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af64335",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3) Embedded\n",
    "\n",
    "\n",
    "### Préparation des données\n",
    "\n",
    "Exécutez le code ci-dessous.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13da5d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "X_train shape: (1676, 500)\n",
      "X_test shape: (420, 500)\n",
      "y_train shape: 1676\n",
      "y_test shape: 420\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Préparation des données: reprendre df_union_intersect et ne prendre que les colonnes qui sont dans features_names_wrapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df_union_intersect.loc[:, df_union_intersect.columns.intersection(features_names_wrapper)]\n",
    "y = df_union_intersect[\"leukemia_class\"].to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"-----------\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {len(y_train)}\")\n",
    "print(f\"y_test shape: {len(y_test)}\")\n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c87666",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "En vous inspirant de l'utilisation faite de Random Forest pour la sélection d'attribut, utilisez [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) pour créer un classificateur avec les données générées ci-dessus. Vous pouvez lire [cet article de DataCamp](https://www.datacamp.com/tutorial/random-forests-classifier-python) si vous voulez vous raffraichir sur Random Forest. \n",
    "\n",
    "Une fois le classificateur créé, déterminez son accuracy puis générez la liste de l'importance de chaque feature. Jouez brièvement avec les paramètres possibles améliorer l'accuracy. \n",
    "\n",
    "Note: \n",
    "- Le paramètre n_jobs=-1 vous permet de paralléliser le travail sur tous vos coeurs. Avec 8 coeurs le travail prend environ 2 minutes. \n",
    "- Nous voulons tester l'importance de toutes les features, on va donc toutes les tester: utilisez le paramètre \"**max_features=len(X.columns)**\"\n",
    "- Vous pouvez aussi prendre un grand nombre d'estimateurs e.g. \"**n_estimators=400**\"\n",
    "- Suivez le code donné en commentaires\n",
    "- Une fois le modèle entrainé, les \"feature importances\" sont accessibles dans *rf_clf.feature_importances_*\n",
    "- Vous pouvez générer une pandas.Series en donnant les noms de features comme indexes et utiliser la fonction sort_values(ascending=False) pour trier les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46f24df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8642857142857143\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1, max_features=len(X.columns), n_estimators=400, random_state=0) # COMPLETEZ\n",
    "rf_clf.fit(X_train, y_train) # COMPLETEZ\n",
    "\n",
    "y_pred = rf_clf.predict(X_test) # COMPLETEZ\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "feature_imp_RF = pd.Series(rf_clf.feature_importances_, index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb629f",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- L'algorithme Random Forest va construire un ensemble d'arbres de décisions de petite taille contrairement au Decision Tree Classifier qui va construire un arbre de grande taille. Décrivez les paramètres *n_estimators*, *max_depth* et *min_samples_leaf* de RandomForestClassifier. \n",
    "\n",
    "- Décrivez les résultats obtenus. Que représente la \"feature importance\" ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "function",
   "metadata": {},
   "source": [
    "n_estimators = nombre d'arbres\n",
    "max_depth = profondeur maximale de chaque arbre\n",
    "min_samples_leaf = nombre minimum d'énchantillons qu'une feuille doit contenir, ce paramètre est pour élaguer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb51286",
   "metadata": {},
   "source": [
    "### Support Vector Machine - SVC\n",
    "\n",
    "Comme pour Random Forest, nous voulons ici créer un modèle qui nous permet d'avoir l'importance que chaque feature. Nous alons de nouveau utiliser [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). Pour pouvoir obtenir l'importance des features, nous devons utiliser un kernel lineaire. Inspirez-vous du code en commentaires ci-dessous pour créer un classificateur. \n",
    "\n",
    "Une fois le classificateur créé, déterminez son accuracy puis générez la liste de l'importance de chaque feature. Jouez avec les paramètres possibles pour trouver une $accuracy > 93\\%$. \n",
    "\n",
    "Note: \n",
    " \n",
    "- Les importances d'attributs peuvent être obtenus avec *abs(svc_clf.coef_[0])*\n",
    "- Les paramètres par défaut donnent déja de bons résultats\n",
    "- Suppor Vector Machine: SVC = Classificateur, SVR = Régression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ec54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(...) # COMPLETEZ\n",
    "svc_clf.fit(...) # COMPLETEZ\n",
    "\n",
    "y_pred = # COMPLETEZ\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "feature_imp_SVC = pd.Series(...).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc38ba",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Final feature selection\n",
    "\n",
    "Nous avons maintenant nos deux *pandas.Series* contenant les features et leurs importances obtenues avec Random Forest et SVM que nous mettons ci-dessous dans un joli DataFrame appelé features_RF_SVC. Après avoir vérifié que tout est dans le bon sens, ce qui normalement ne devrait pas poser problème, faites ceci:\n",
    "\n",
    "- Pour choisir les features les plus importantes, créez une troisième colonne contenant la **somme des deux autres** puis ordrez par ordre décroissant.\n",
    "\n",
    "- Sélectionnez en suite les N_first (210) features les plus importantes et récupérez la liste des indexes (df.index). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crée un DataFrame contenant les importances des features selon chaque méthode\n",
    "\n",
    "features_RF_SVC = pd.DataFrame(columns = ['Features_imp_SVC', 'Features_imp_RF'])\n",
    "features_RF_SVC['Features_imp_SVC'] = feature_imp_SVC\n",
    "features_RF_SVC['Features_imp_RF'] = feature_imp_RF\n",
    "\n",
    "# Vérifiez que les données ont bien été introduites dans le DataFrame selon le bon indexe\n",
    "\n",
    "feature_imp_RF.loc[\"227998_at\"]\n",
    "feature_imp_SVC.loc[\"227998_at\"]\n",
    "features_RF_SVC.loc[\"227998_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_RF_SVC[\"nouvelle_colonne\"] = # COMPLETEZ\n",
    "\n",
    "features_RF_SVC.sort_values(...) # COMPLETEZ\n",
    "\n",
    "\n",
    "N_first = 210\n",
    "\n",
    "n_first_idx = list(features_RF_SVC.iloc[:N_first,:].index)\n",
    "\n",
    "print(f\"Total selected features: {len(n_first_idx)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba4323",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "Avant d'évaluer la sélection, discutez de la méthode choisies pour garder les 210 premières variables. Quels sont les avantages ou les inconvénients d'utiliser la somme  des \"feature importance\" ? Utiliser le ranking (1er, 2ème, etc) représente-t-il une alternative envisageable ? Pourquoi ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaba7dc",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcae6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7e355",
   "metadata": {},
   "source": [
    "Nous construisons en suite nos splits de données pour pouvoir entrainer nos models avec les 210 variables les plus pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des données avec les 210 premières features sélectionnées\n",
    "\n",
    "X_n_first = df_union_intersect.loc[:, n_first_idx]\n",
    "y_n_first = df_union_intersect[\"leukemia_class\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f21ff",
   "metadata": {},
   "source": [
    "---\n",
    "Ci-dessous vous trouverez une fonction pour évaluer vos features sélectionnez. \n",
    "\n",
    "### Question : \n",
    "\n",
    "- Décrivez rapidement ce que fait la fonction \n",
    "- Pourquoi utiliser trois classificateurs différents?\n",
    "- Comment rendre la méthode d'évaluation plus robuste ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d6d2b",
   "metadata": {},
   "source": [
    "*Réponse* :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1232d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_selection(X, y, show=True):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)    \n",
    "    common_labels = np.unique(y_test)\n",
    "    \n",
    "    models = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier()\n",
    "    ]\n",
    "    \n",
    "    accuracies = []\n",
    "    combined_cm = None\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))        \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=common_labels)\n",
    "        \n",
    "        # Sum the confusion matrices element-wise.\n",
    "        if combined_cm is None:\n",
    "            combined_cm = cm\n",
    "        else:\n",
    "            combined_cm += cm\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(combined_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=common_labels, yticklabels=common_labels)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Combined Confusion Matrix (Sum of all models)\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\nMean Accuracy across models: {mean_accuracy:.4f}, with standard deviation: {np.std(accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisez la fonction pour évaluer la performance de votre sélection de features n_first_idx\n",
    "\n",
    "# COMPLETEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d22467",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ensemble Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9aad96",
   "metadata": {},
   "source": [
    "Nous avons exploré trois types de méthodes de sélection de features : filter, wrapper et embedded. Nous avons combiné de différentes manières les résultats obtenus par ces méthodes, approchant ainsi ce qu'on appelle l'ensemble feature sélection, c'est-à-dire l'utilisation et la combinaison de plusieurs méthodes de FS, à l'image de l'ensemble learning.\n",
    "\n",
    "Nous vous proposons désormais d'utiliser un paquet Python en cours de développement qui automatise les différentes étapes de l'ensemble feature sélection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978bb42",
   "metadata": {},
   "source": [
    "Nous avons exploré trois types de méthodes de sélection de features : filter, wrapper et embedded. Nous avons combiné leurs résultats de différentes manières, approchant ainsi l’ensemble feature sélection, qui consiste à utiliser et combiner plusieurs méthodes de FS, à l’image de l’ensemble learning.\n",
    "\n",
    "Pour automatiser ces différentes étapes, nous vous proposons d’utiliser un paquet Python en cours de développement.\n",
    "\n",
    "Code disponible sur GitHub : [ensemblefs](https://github.com/arthurbabey/ensemblefs/)  \n",
    "Documentation : [Accéder à la doc](https://arthurbabey.github.io/ensemblefs/)  \n",
    "\n",
    "\n",
    "Installation :\n",
    "```bash\n",
    "pip install git+https://github.com/arthurbabey/ensemblefs.git\n",
    "```\n",
    "\n",
    "Le projet est en cours de développement, si vous observez des bugs ou des améliorations possibles, n’hésitez pas à les signaler !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe35bb",
   "metadata": {},
   "source": [
    "Voici une rapide présentation de la méthodologie mise en place lors de la sélection avec ensemble dans ce paquet :\n",
    "\n",
    "1. Utiliser plusieurs sélecteurs pour obtenir des listes de features.  \n",
    "2. Combiner ces listes via une stratégie de fusion (par défaut, l'union des intersections).  \n",
    "3. Répéter la sélection N fois pour créer divers groupes, chaque groupe étant la combinaison de plusieurs listes de features.  \n",
    "4. Calculer des métriques de performance et de stabilité.  \n",
    "5. Employer une méthode de type Pareto pour optimiser la sélection en fonction de la performance et de la stabilité.  \n",
    "6. Comparer les groupes, identifier les meilleurs, et retourner leur liste de features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cba1ec",
   "metadata": {},
   "source": [
    "Comme le processus d'ensemble feature sélection peut être couteux en temps nous allons l'utiliser pour la dernière étape : passer des 879 features sélectionner après la méthode embedded jusqu'à une liste final de 210 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les données après l'étape de sélection des features embedded \n",
    "RF_SVC_index = list(features_RF_SVC.index)\n",
    "\n",
    "df_efs = df_union_intersect.loc[:, RF_SVC_index+[\"leukemia_class\"]]\n",
    "df_efs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4741336",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer une instance FeatureSelectionPipeline en définissant chaque attributs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemblefs import FeatureSelectionPipeline\n",
    "\n",
    "data = df_efs.rename(columns={\"leukemia_class\": \"target\"}) # créer une colonne target\n",
    "data[\"target\"] = data[\"target\"].astype(\"category\").cat.codes # convertir la colonne target en catégorique\n",
    "\n",
    "fs_methods = [\"random_forest_selector\", \"svm_selector\", \"lasso_selector\", \"xgboost_selector\"]\n",
    "merging_strategy = \"union_of_intersections_merger\"\n",
    "num_repeats = 5 \n",
    "task = \"classification\" \n",
    "num_features_to_select = 210\n",
    "metrics = [\"logloss\", \"f1_score\"]\n",
    "min_group_size = 2\n",
    "fill = True\n",
    "random_state = 123\n",
    "n_jobs = 5\n",
    "\n",
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=data, # pandas dataset avec la colonne target\n",
    "    fs_methods=fs_methods, # list des méthodes de sélection de features, soit en utlisant le nom de la méthode soit en créant un objet de la classe de la méthode de sélection\n",
    "    merging_strategy=merging_strategy, # stratégie de fusion des features sélectionnées\n",
    "    num_repeats=num_repeats, # nombre de répétitions pour chaque méthode de sélection de features\n",
    "    task=task, # classification ou régression\n",
    "    num_features_to_select=num_features_to_select, # nombre de features à sélectionner\n",
    "    metrics=metrics, # liste des métrique de performance à utiliser pour évaluer les features sélectionnées (minimum 1)\n",
    "    min_group_size=min_group_size, # taille minimale du groupe de features sélectionnées\n",
    "    fill=fill, # combler les features sélectionnées jusqu'à num_features_to_select si la stratégie de fusion ne les atteint pas\n",
    "    random_state=random_state, # random seed\n",
    "    n_jobs=n_jobs # nombre de coeurs à utiliser pour le calcul parallèle\n",
    ")\n",
    "\n",
    "selected_features, _, _ = pipeline.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af064bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_efs[list(selected_features)], df_efs[\"leukemia_class\"]\n",
    "\n",
    "evaluate_feature_selection(X, y, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182e490",
   "metadata": {},
   "source": [
    "---\n",
    "Maintenant, essayez de modifier les paramètres pour voir si vous pouvez améliorer les résultats. Vous pouvez ajuster ceux proposés dans la prochaine cellule.\n",
    "\n",
    "Expérimentez avec différents réglages et expliquez vos choix. Inutile de chercher exhaustivement les meilleurs paramètres, car la méthode est coûteuse en temps de calcul.\n",
    "\n",
    "Vous pouvez trouver dans le code ou dans la documentations les différents feature selectors possible ainsi que les metrics possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0170326",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_methods = # COMPLETEZ\n",
    "metrics = # COMPLETEZ\n",
    "min_group_size = # COMPLETEZ\n",
    "\n",
    "\n",
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=data,\n",
    "    fs_methods=fs_methods,\n",
    "    merging_strategy=merging_strategy,\n",
    "    num_repeats=num_repeats,\n",
    "    task=task,\n",
    "    num_features_to_select=num_features_to_select,\n",
    "    metrics=metrics,\n",
    "    min_group_size=min_group_size,\n",
    "    fill=fill,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "selected_features_2, _ , _ = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f734d",
   "metadata": {},
   "source": [
    "*Justification:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e52b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b57d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_union[list(selected_features_2)], df_union[\"leukemia_class\"]\n",
    "\n",
    "evaluate_feature_selection(X, y, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00832c6c",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "- Pourquoi est-il important lors de feature sélection par ensemble d'utiliser des sélecteurs différents? \n",
    "- Qu'est-ce que le paramètre min_group_size et comment influence-t-il la sélection des features ? \n",
    "- Comparez les résultats obtenus lors de l'évaluation de selected_features et selected_features_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e30ec",
   "metadata": {},
   "source": [
    "*Réponse:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f0925",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4ee8f",
   "metadata": {},
   "source": [
    "## Visualisation et analyse\n",
    "\n",
    "- Analyser une des matrices de confusion calculée ci-dessus. Quelle erreure de prédiction peut être plus grave que d'autres ? \n",
    "- On vous donne ci-dessous la liste des 210 variables les plus pértinentes obtenues lors d'un projet d'une durée de 3 ans avec beaucoup plus de moyens (temps, ressources, experts médicaux, etc). Comparez cette liste avec les listes obtenues dans ce TP (les 210 obtenus après toute les étapes et les 210 obtenus avec l'ensemble feature selection) et discutez rapidement les résultats. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199cc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des 210 variables\n",
    "# Comparez avec vos données obtenues\n",
    "import pickle\n",
    "\n",
    "# read pickle \n",
    "with open(\"./data/list_210_features.pickle\", \"rb\") as fp:   #Pickling\n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f9eac",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e143fa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60215329",
   "metadata": {},
   "source": [
    "Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
