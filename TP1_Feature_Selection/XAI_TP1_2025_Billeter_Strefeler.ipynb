{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a54cc36",
   "metadata": {},
   "source": [
    "# XAI - 2025 - TP1 - Feature Selection\n",
    "\n",
    "\n",
    "But du TP: \n",
    "\n",
    "- Explorer plus en profondeur la sélection d'attributs (Feature Selection) dans une optique d'interprétabilité. Répondez aux questions et complétez le code directement dans le notebook et n'oubliez pas de changer le nom du fichier avec votre nom et prénom. \n",
    "\n",
    "Rendu du TP: \n",
    "\n",
    "- Durée 2 semaines\n",
    "- Mercredi 12 mars 2025 23h59, Cyberlearn\n",
    "\n",
    "Description: \n",
    "\n",
    "   - Le dataset [MILE](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE13159) contient pour ~2000 patients les données d'expression d'environ 54'000 gènes. Afin d'accélérer le début de ce TP, les features ont déjà été écrémées grâce à trois méthodes différentes (chi2, mutual_information et f_score) qui ont chacunes retourné les 5000 meilleures variables (features). \n",
    "\n",
    "Dans ce travail vous devrez: \n",
    "\n",
    "1. Comparer les features sélectionnées par les premières méthodes de filtre et en retourner un subset adéquat.\n",
    "\n",
    "     \n",
    "2. Appliquer méthodes wrapper sur le dataset choisi\n",
    "\n",
    "    a. RFE-RF\n",
    "    \n",
    "    b. RFE-SVM\n",
    "\n",
    "\n",
    "3. Entrainer un modèle et en extraire les features les plus importantes\n",
    "\n",
    "    a. Random Forest (RF)\n",
    "    \n",
    "    b. Support Vector Machine (SVM)\n",
    "    \n",
    "    \n",
    "4. Sélectionner les attributs les plus pertinents\n",
    "\n",
    "    a. Entrainer des modèles (RF et SVM) avec le dataset réduit \n",
    "\n",
    "\n",
    "5. Essayez une méthode d'ensemble pour la feature selection\n",
    "\n",
    "\n",
    "6. Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71be488",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Filter methods\n",
    "\n",
    "Trois méthodes de *features selection* ont été préalablement appliquées au dataset original afin de vous éviter un temps de calcul trop long. De ce dataset, qui contient 54'000 attributs (ou features, ou variables), chaque méthode en a retenu 5000 qui sont présents dans les trois fichiers csv joints et qui sont lus ci-dessous. \n",
    "\n",
    "- Explorez rapidement les données\n",
    "- Exécutez et comprenez le code ci-dessous et répondez aux questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si nécessaire installez les packages suivants:\n",
    "\n",
    "#!conda install scikit-learn\n",
    "#!pip install matplotlib_venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03554d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the three datasets with each 5000 variables previously selected with the \n",
    "# sklearn.SelectKBest method with the following scoring functions (filters)\n",
    "\n",
    "# - mutual_information_score\n",
    "# - chi2\n",
    "# - f_classifier\n",
    "\n",
    "# Note: leukemia_class will be considered a feature and replaced at the end !\n",
    "\n",
    "features_df_mutual_5000 = pd.read_csv(\"./data/features_df_mutual_5000.csv\", index_col='ID_REF')\n",
    "features_df_chi2_5000 = pd.read_csv(\"./data/features_df_chi2_5000.csv\", index_col='ID_REF')\n",
    "features_df_fc_5000 = pd.read_csv(\"./data/features_df_fc_5000.csv\", index_col='ID_REF')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a50566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorez rapidement les 3 DataFrames pour bien comprendre les données. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f82ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names (features names / noms d'attributs)\n",
    "cols_mutual = list(features_df_mutual_5000.columns)\n",
    "cols_chi2 = list(features_df_chi2_5000.columns)\n",
    "cols_fc = list(features_df_fc_5000.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0b3e4",
   "metadata": {},
   "source": [
    "### Total features union\n",
    "\n",
    "Si l'on prend la totalité des variables choisies par nos trois méthodes, nous obtenons 7615 variables différentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total features union\n",
    "all_features_union = set(cols_mutual + cols_chi2 + cols_fc)\n",
    "print(len(all_features_union))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3759f7",
   "metadata": {},
   "source": [
    "### Total features intersection\n",
    "\n",
    "Si l'on choisi de prendre uniquement les variables sélectionnées par nos trois méthodes, nous obtenons 2458 variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60daecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total features intersection\n",
    "all_features_intersect = set(cols_mutual).intersection(cols_chi2).intersection(cols_fc)\n",
    "print(len(all_features_intersect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e7b4b",
   "metadata": {},
   "source": [
    "### Total features union of intersections\n",
    "\n",
    "Nous pouvons choisir les variables qui ont été retenues par au moins deux méthodes en prenant l'union des intersections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7556bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total features union of intersections\n",
    "\n",
    "# Intersection between the 5000 columns of mutual_information and the 5000 of chi2\n",
    "features_mutual_n_chi2 = set(cols_mutual).intersection(cols_chi2)\n",
    "l_mutual_chi2 = len(features_mutual_n_chi2)\n",
    "print(f\"Intersection between mutual and chi2: {l_mutual_chi2}\")\n",
    "\n",
    "# Same with mutual_information and f_classifier\n",
    "features_mutual_n_fc = set(cols_mutual).intersection(cols_fc)\n",
    "l_mutual_fc = len(features_mutual_n_fc)\n",
    "print(f\"Intersection between mutual and fc: {l_mutual_fc}\")\n",
    "\n",
    "# Same with f_classifier and chi2\n",
    "features_fc_n_chi2 = set(cols_fc).intersection(cols_chi2)\n",
    "l_fc_chi2 = len(features_fc_n_chi2)\n",
    "print(f\"Intersection between fc and chi2: {l_fc_chi2}\")\n",
    "\n",
    "# Intersection between the three (length)\n",
    "l_fc_chi2_mutual = len(set(cols_fc).intersection(cols_chi2).intersection(cols_mutual))\n",
    "print(f\"Intersection between mutual, fc and chi2: {l_fc_chi2_mutual}\")\n",
    "\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "# Creating a set removes the duplicates (intersection between the three are present multiple times until now)\n",
    "all_features_union_of_intersect = list(set(list(features_mutual_n_chi2) + \n",
    "                                           list(features_mutual_n_fc) + \n",
    "                                           list(features_fc_n_chi2)))\n",
    "\n",
    "print(f\"Union of intersections {len(all_features_union_of_intersect)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f020e1",
   "metadata": {},
   "source": [
    "Voici un petit diagramme de Venn pour vous aider à visualiser les features en commun entre les différentes méthodes (calculs fait à la main à partir des intersections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    " \n",
    "v=venn3(subsets = (472, 2024, 116, 186,1954,402,2458), set_labels = ('Mutual information', 'Chi2', 'f classifier'))\n",
    "#v.get_label_by_id('A').set_text('My Favourite group!')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1651c",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- Décrivez le dataset MILE et son contenu. D'où vient-il et quel est son but ? Que représentent les données ? Donnez des informations sur les variables indépendantes, sur la variable dépendante, la tâche de machine learning à effectuer etc. \n",
    "- Donnez une description des trois méthodes utilisées pour le premier filtre\n",
    "- Pourquoi utiliser des méthodes simples commes celles-ci pour une première étape de filtre ?\n",
    "- Nous choisissons de garder l'union des intersections des features (création du DF ci-dessous). D'après vous, pourquoi faire ce choix plutôt que de garder la totalité des features sélectionnées par les trois méthodes (union) ou les features en commun entre les trois méthodes (intersection) ?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb1ca4",
   "metadata": {},
   "source": [
    "Réponses:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08509d1c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24606a36",
   "metadata": {},
   "source": [
    "On crée notre DataFrame *df_union_intersect* qui va être utilisé pour la suite du TP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0653ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column lists from each method\n",
    "mutual_columns = features_df_mutual_5000.columns.tolist()\n",
    "chi2_unique = [col for col in features_df_chi2_5000.columns if col not in mutual_columns]\n",
    "fc_unique   = [col for col in features_df_fc_5000.columns if col not in (mutual_columns + chi2_unique)]\n",
    "\n",
    "# Concatenate the selected columns to form the union DataFrame\n",
    "df_union = pd.concat([\n",
    "    features_df_mutual_5000[mutual_columns],\n",
    "    features_df_chi2_5000[chi2_unique],\n",
    "    features_df_fc_5000[fc_unique]\n",
    "], axis=1)\n",
    "\n",
    "# Retain only the features selected by at least two methods (union of intersections)\n",
    "df_union_intersect = df_union.loc[:, all_features_union_of_intersect]\n",
    "\n",
    "# Retain only the features selected by all three methods (intersection)\n",
    "df_intersect = df_union.loc[:, list(all_features_intersect)]\n",
    "\n",
    "# Move 'leukemia_class' to the last column\n",
    "leukemia_class = df_union_intersect.pop(\"leukemia_class\")\n",
    "df_union_intersect[\"leukemia_class\"] = leukemia_class\n",
    "\n",
    "df_union_intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e48cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1411063",
   "metadata": {},
   "source": [
    "## 2) Wrapper methods\n",
    "\n",
    "\n",
    "Nous allons maintenant utiliser deux *wrapper methods* afin de réduire notre sélection d'environ 5'000 attributs à environ 500 (ordre de grandeur). Pour cela nous allons utiliser la Recurisve Features Elimination (RFE) de scikit-learn avec Random Forest et Support Vector Machine. \n",
    "\n",
    "(*Note: sans Cross Validation (rfecv) car très demandant en ressources*)\n",
    "\n",
    "\n",
    "- Répondez aux questions \n",
    "- RFE-RF: Exécutez le code donné et répondez aux questions\n",
    "- RFE-SVM: Complétez le code demandé et répondez aux questions\n",
    "- Sélectionnez les features que vous garderez pour la prochaine étape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a19235",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "- Écrivez une courte description de ce que sont les méthodes \"wrapper\" pour la sélection d'attributs. Comment fonctionne RFE (implémentation de sklearn) \n",
    "- Pourquoi est-il possible de l'utiliser avec Random Forest et Support Vector Machine (SVM) ?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3609813",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f5a2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données \n",
    "\n",
    "X_uoi, y_uoi = df_union_intersect.drop(columns=\"leukemia_class\"), df_union_intersect[\"leukemia_class\"]\n",
    "\n",
    "X_i, y_i = df_intersect.drop(columns=\"leukemia_class\"), df_intersect[\"leukemia_class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ad0e7",
   "metadata": {},
   "source": [
    "### RFE-RF\n",
    "\n",
    "Exécuter le code donné ci-dessous. Complétez les commentaires (les # sans rien) dans le code afin d'expliquer ce qui est fait puis répondez aux questions.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Attention:</b> Temps d'exécution avec les paramètres actuels: RFE-RF (50 sec) / RFE-SVM (5 minutes avec LinearSVC, 30 secondes avec SVC)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "#---------------\n",
    "\n",
    "# \n",
    "selector = RFE(estimator=RandomForestClassifier(random_state=0, \n",
    "                                                n_estimators=25, \n",
    "                                                max_depth=10), \n",
    "               n_features_to_select=500, \n",
    "               step=0.02)\n",
    "\n",
    "# \n",
    "selector = selector.fit(X_uoi, y_uoi)\n",
    "\n",
    "# \n",
    "features_names_RFERF = X_uoi.columns[selector.support_]\n",
    "\n",
    "#---------------\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# without step: 1581 sec\n",
    "# with step: 49 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06338fc9",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "On cherche à retirer les variables qui sont les plus mauvais prédicteurs. Quelle influence cela a-t-il sur le choix des paramètres de notre RandomForestClassifier ? En d'autres termes: Que changeriez-vous si vous utilisiez Random Forest pour créer un modèle performant au lieu de l'utiliser pour éliminer les plus mauvaises features ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5b2f5",
   "metadata": {},
   "source": [
    "*Réponse*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919885a4",
   "metadata": {},
   "source": [
    "---\n",
    "### RFE-SVM\n",
    "\n",
    "En vous basant sur le code de RFE-RF ci-dessus, écrivez le code pour une RFE avec cette fois-ci l'estimateur SVM. \n",
    "\n",
    "Utilisez les paramètres suivant:\n",
    "- Pour RFE: \n",
    "    - estimator = SVC\n",
    "    - N_features: 500\n",
    "    - step=0.05\n",
    "\n",
    "\n",
    "- Pour SVC\n",
    "    - Kernel = 'linear'\n",
    "    - C=1\n",
    "    - max_iter=1000\n",
    "\n",
    "Gardez les noms des 500 features choisies dans une variable nommée *features_names_RFESVM*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "features_names_RFESVM = # COMPLETEZ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedefbd9",
   "metadata": {},
   "source": [
    "### Features retenues par les deux méthodes\n",
    "\n",
    "Créez une liste nommée \"**features_names_wrapper**\" avec l'**union** des features retenues. Vous devriez obtenir environ 8-900 features en tout. Affichez vos résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a817f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union des features de features_names_RFESVM et features_names_RFERF\n",
    "\n",
    "features_names_wrapper = # COMPLETEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349168d",
   "metadata": {},
   "source": [
    "### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2917d68",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Pourquoi garder les ~8-900 features issues de l'union et pas uniquement les ~100 de l'intersection ?\n",
    "- Dans un contexte plus réél avec du temps et des ressources en quantité, comment auriez-vous amélioré l'utilisation de RFE pour faire une sélection encore plus pértinente de variables ?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d844a3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3feef",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af64335",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Embedded\n",
    "\n",
    "\n",
    "### Préparation des données\n",
    "\n",
    "Exécutez le code ci-dessous.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données: reprendre df_union_intersect et ne prendre que les colonnes qui sont dans features_names_wrapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df_union_intersect.loc[:, df_union_intersect.columns.intersection(features_names_wrapper)]\n",
    "y = df_union_intersect[\"leukemia_class\"].to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"-----------\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {len(y_train)}\")\n",
    "print(f\"y_test shape: {len(y_test)}\")\n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c87666",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "En vous inspirant de l'utilisation faite de Random Forest pour la sélection d'attribut, utilisez [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) pour créer un classificateur avec les données générées ci-dessus. Vous pouvez lire [cet article de DataCamp](https://www.datacamp.com/tutorial/random-forests-classifier-python) si vous voulez vous raffraichir sur Random Forest. \n",
    "\n",
    "Une fois le classificateur créé, déterminez son accuracy puis générez la liste de l'importance de chaque feature. Jouez brièvement avec les paramètres possibles améliorer l'accuracy. \n",
    "\n",
    "Note: \n",
    "- Le paramètre n_jobs=-1 vous permet de paralléliser le travail sur tous vos coeurs. Avec 8 coeurs le travail prend environ 2 minutes. \n",
    "- Nous voulons tester l'importance de toutes les features, on va donc toutes les tester: utilisez le paramètre \"**max_features=len(X.columns)**\"\n",
    "- Vous pouvez aussi prendre un grand nombre d'estimateurs e.g. \"**n_estimators=400**\"\n",
    "- Suivez le code donné en commentaires\n",
    "- Une fois le modèle entrainé, les \"feature importances\" sont accessibles dans *rf_clf.feature_importances_*\n",
    "- Vous pouvez générer une pandas.Series en donnant les noms de features comme indexes et utiliser la fonction sort_values(ascending=False) pour trier les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f24df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(...) # COMPLETEZ\n",
    "rf_clf.fit(...) # COMPLETEZ\n",
    "\n",
    "y_pred = # COMPLETEZ\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "feature_imp_RF = pd.Series(..., index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb629f",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- L'algorithme Random Forest va construire un ensemble d'arbres de décisions de petite taille contrairement au Decision Tree Classifier qui va construire un arbre de grande taille. Décrivez les paramètres *n_estimators*, *max_depth* et *min_samples_leaf* de RandomForestClassifier. \n",
    "\n",
    "- Décrivez les résultats obtenus. Que représente la \"feature importance\" ?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb51286",
   "metadata": {},
   "source": [
    "### Support Vector Machine - SVC\n",
    "\n",
    "Comme pour Random Forest, nous voulons ici créer un modèle qui nous permet d'avoir l'importance que chaque feature. Nous alons de nouveau utiliser [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). Pour pouvoir obtenir l'importance des features, nous devons utiliser un kernel lineaire. Inspirez-vous du code en commentaires ci-dessous pour créer un classificateur. \n",
    "\n",
    "Une fois le classificateur créé, déterminez son accuracy puis générez la liste de l'importance de chaque feature. Jouez avec les paramètres possibles pour trouver une $accuracy > 93\\%$. \n",
    "\n",
    "Note: \n",
    " \n",
    "- Les importances d'attributs peuvent être obtenus avec *abs(svc_clf.coef_[0])*\n",
    "- Les paramètres par défaut donnent déja de bons résultats\n",
    "- Suppor Vector Machine: SVC = Classificateur, SVR = Régression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ec54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(...) # COMPLETEZ\n",
    "svc_clf.fit(...) # COMPLETEZ\n",
    "\n",
    "y_pred = # COMPLETEZ\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "feature_imp_SVC = pd.Series(...).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc38ba",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Final feature selection\n",
    "\n",
    "Nous avons maintenant nos deux *pandas.Series* contenant les features et leurs importances obtenues avec Random Forest et SVM que nous mettons ci-dessous dans un joli DataFrame appelé features_RF_SVC. Après avoir vérifié que tout est dans le bon sens, ce qui normalement ne devrait pas poser problème, faites ceci:\n",
    "\n",
    "- Pour choisir les features les plus importantes, créez une troisième colonne contenant la **somme des deux autres** puis ordrez par ordre décroissant.\n",
    "\n",
    "- Sélectionnez en suite les N_first (210) features les plus importantes et récupérez la liste des indexes (df.index). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crée un DataFrame contenant les importances des features selon chaque méthode\n",
    "\n",
    "features_RF_SVC = pd.DataFrame(columns = ['Features_imp_SVC', 'Features_imp_RF'])\n",
    "features_RF_SVC['Features_imp_SVC'] = feature_imp_SVC\n",
    "features_RF_SVC['Features_imp_RF'] = feature_imp_RF\n",
    "\n",
    "# Vérifiez que les données ont bien été introduites dans le DataFrame selon le bon indexe\n",
    "\n",
    "feature_imp_RF.loc[\"227998_at\"]\n",
    "feature_imp_SVC.loc[\"227998_at\"]\n",
    "features_RF_SVC.loc[\"227998_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_RF_SVC[\"nouvelle_colonne\"] = # COMPLETEZ\n",
    "\n",
    "features_RF_SVC.sort_values(...) # COMPLETEZ\n",
    "\n",
    "\n",
    "N_first = 210\n",
    "\n",
    "n_first_idx = list(features_RF_SVC.iloc[:N_first,:].index)\n",
    "\n",
    "print(f\"Total selected features: {len(n_first_idx)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba4323",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "Avant d'évaluer la sélection, discutez de la méthode choisies pour garder les 210 premières variables. Quels sont les avantages ou les inconvénients d'utiliser la somme  des \"feature importance\" ? Utiliser le ranking (1er, 2ème, etc) représente-t-il une alternative envisageable ? Pourquoi ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaba7dc",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcae6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7e355",
   "metadata": {},
   "source": [
    "Nous construisons en suite nos splits de données pour pouvoir entrainer nos models avec les 210 variables les plus pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des données avec les 210 premières features sélectionnées\n",
    "\n",
    "X_n_first = df_union_intersect.loc[:, n_first_idx]\n",
    "y_n_first = df_union_intersect[\"leukemia_class\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f21ff",
   "metadata": {},
   "source": [
    "---\n",
    "Ci-dessous vous trouverez une fonction pour évaluer vos features sélectionnez. \n",
    "\n",
    "### Question : \n",
    "\n",
    "- Décrivez rapidement ce que fait la fonction \n",
    "- Pourquoi utiliser trois classificateurs différents?\n",
    "- Comment rendre la méthode d'évaluation plus robuste ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d6d2b",
   "metadata": {},
   "source": [
    "*Réponse* :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1232d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_selection(X, y, show=True):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)    \n",
    "    common_labels = np.unique(y_test)\n",
    "    \n",
    "    models = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier()\n",
    "    ]\n",
    "    \n",
    "    accuracies = []\n",
    "    combined_cm = None\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))        \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=common_labels)\n",
    "        \n",
    "        # Sum the confusion matrices element-wise.\n",
    "        if combined_cm is None:\n",
    "            combined_cm = cm\n",
    "        else:\n",
    "            combined_cm += cm\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(combined_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=common_labels, yticklabels=common_labels)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Combined Confusion Matrix (Sum of all models)\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\nMean Accuracy across models: {mean_accuracy:.4f}, with standard deviation: {np.std(accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisez la fonction pour évaluer la performance de votre sélection de features n_first_idx\n",
    "\n",
    "# COMPLETEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d22467",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ensemble Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9aad96",
   "metadata": {},
   "source": [
    "Nous avons exploré trois types de méthodes de sélection de features : filter, wrapper et embedded. Nous avons combiné de différentes manières les résultats obtenus par ces méthodes, approchant ainsi ce qu'on appelle l'ensemble feature sélection, c'est-à-dire l'utilisation et la combinaison de plusieurs méthodes de FS, à l'image de l'ensemble learning.\n",
    "\n",
    "Nous vous proposons désormais d'utiliser un paquet Python en cours de développement qui automatise les différentes étapes de l'ensemble feature sélection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978bb42",
   "metadata": {},
   "source": [
    "Nous avons exploré trois types de méthodes de sélection de features : filter, wrapper et embedded. Nous avons combiné leurs résultats de différentes manières, approchant ainsi l’ensemble feature sélection, qui consiste à utiliser et combiner plusieurs méthodes de FS, à l’image de l’ensemble learning.\n",
    "\n",
    "Pour automatiser ces différentes étapes, nous vous proposons d’utiliser un paquet Python en cours de développement.\n",
    "\n",
    "Code disponible sur GitHub : [ensemblefs](https://github.com/arthurbabey/ensemblefs/)  \n",
    "Documentation : [Accéder à la doc](https://arthurbabey.github.io/ensemblefs/)  \n",
    "\n",
    "\n",
    "Installation :\n",
    "```bash\n",
    "pip install git+https://github.com/arthurbabey/ensemblefs.git\n",
    "```\n",
    "\n",
    "Le projet est en cours de développement, si vous observez des bugs ou des améliorations possibles, n’hésitez pas à les signaler !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe35bb",
   "metadata": {},
   "source": [
    "Voici une rapide présentation de la méthodologie mise en place lors de la sélection avec ensemble dans ce paquet :\n",
    "\n",
    "1. Utiliser plusieurs sélecteurs pour obtenir des listes de features.  \n",
    "2. Combiner ces listes via une stratégie de fusion (par défaut, l'union des intersections).  \n",
    "3. Répéter la sélection N fois pour créer divers groupes, chaque groupe étant la combinaison de plusieurs listes de features.  \n",
    "4. Calculer des métriques de performance et de stabilité.  \n",
    "5. Employer une méthode de type Pareto pour optimiser la sélection en fonction de la performance et de la stabilité.  \n",
    "6. Comparer les groupes, identifier les meilleurs, et retourner leur liste de features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cba1ec",
   "metadata": {},
   "source": [
    "Comme le processus d'ensemble feature sélection peut être couteux en temps nous allons l'utiliser pour la dernière étape : passer des 879 features sélectionner après la méthode embedded jusqu'à une liste final de 210 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les données après l'étape de sélection des features embedded \n",
    "RF_SVC_index = list(features_RF_SVC.index)\n",
    "\n",
    "df_efs = df_union_intersect.loc[:, RF_SVC_index+[\"leukemia_class\"]]\n",
    "df_efs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4741336",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer une instance FeatureSelectionPipeline en définissant chaque attributs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemblefs import FeatureSelectionPipeline\n",
    "\n",
    "data = df_efs.rename(columns={\"leukemia_class\": \"target\"}) # créer une colonne target\n",
    "data[\"target\"] = data[\"target\"].astype(\"category\").cat.codes # convertir la colonne target en catégorique\n",
    "\n",
    "fs_methods = [\"random_forest_selector\", \"svm_selector\", \"lasso_selector\", \"xgboost_selector\"]\n",
    "merging_strategy = \"union_of_intersections_merger\"\n",
    "num_repeats = 5 \n",
    "task = \"classification\" \n",
    "num_features_to_select = 210\n",
    "metrics = [\"logloss\", \"f1_score\"]\n",
    "min_group_size = 2\n",
    "fill = True\n",
    "random_state = 123\n",
    "n_jobs = 5\n",
    "\n",
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=data, # pandas dataset avec la colonne target\n",
    "    fs_methods=fs_methods, # list des méthodes de sélection de features, soit en utlisant le nom de la méthode soit en créant un objet de la classe de la méthode de sélection\n",
    "    merging_strategy=merging_strategy, # stratégie de fusion des features sélectionnées\n",
    "    num_repeats=num_repeats, # nombre de répétitions pour chaque méthode de sélection de features\n",
    "    task=task, # classification ou régression\n",
    "    num_features_to_select=num_features_to_select, # nombre de features à sélectionner\n",
    "    metrics=metrics, # liste des métrique de performance à utiliser pour évaluer les features sélectionnées (minimum 1)\n",
    "    min_group_size=min_group_size, # taille minimale du groupe de features sélectionnées\n",
    "    fill=fill, # combler les features sélectionnées jusqu'à num_features_to_select si la stratégie de fusion ne les atteint pas\n",
    "    random_state=random_state, # random seed\n",
    "    n_jobs=n_jobs # nombre de coeurs à utiliser pour le calcul parallèle\n",
    ")\n",
    "\n",
    "selected_features, _, _ = pipeline.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af064bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_efs[list(selected_features)], df_efs[\"leukemia_class\"]\n",
    "\n",
    "evaluate_feature_selection(X, y, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182e490",
   "metadata": {},
   "source": [
    "---\n",
    "Maintenant, essayez de modifier les paramètres pour voir si vous pouvez améliorer les résultats. Vous pouvez ajuster ceux proposés dans la prochaine cellule.\n",
    "\n",
    "Expérimentez avec différents réglages et expliquez vos choix. Inutile de chercher exhaustivement les meilleurs paramètres, car la méthode est coûteuse en temps de calcul.\n",
    "\n",
    "Vous pouvez trouver dans le code ou dans la documentations les différents feature selectors possible ainsi que les metrics possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0170326",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_methods = # COMPLETEZ\n",
    "metrics = # COMPLETEZ\n",
    "min_group_size = # COMPLETEZ\n",
    "\n",
    "\n",
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=data,\n",
    "    fs_methods=fs_methods,\n",
    "    merging_strategy=merging_strategy,\n",
    "    num_repeats=num_repeats,\n",
    "    task=task,\n",
    "    num_features_to_select=num_features_to_select,\n",
    "    metrics=metrics,\n",
    "    min_group_size=min_group_size,\n",
    "    fill=fill,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "selected_features_2, _ , _ = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f734d",
   "metadata": {},
   "source": [
    "*Justification:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e52b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b57d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_union[list(selected_features_2)], df_union[\"leukemia_class\"]\n",
    "\n",
    "evaluate_feature_selection(X, y, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00832c6c",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "- Pourquoi est-il important lors de feature sélection par ensemble d'utiliser des sélecteurs différents? \n",
    "- Qu'est-ce que le paramètre min_group_size et comment influence-t-il la sélection des features ? \n",
    "- Comparez les résultats obtenus lors de l'évaluation de selected_features et selected_features_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e30ec",
   "metadata": {},
   "source": [
    "*Réponse:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f0925",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4ee8f",
   "metadata": {},
   "source": [
    "## Visualisation et analyse\n",
    "\n",
    "- Analyser une des matrices de confusion calculée ci-dessus. Quelle erreure de prédiction peut être plus grave que d'autres ? \n",
    "- On vous donne ci-dessous la liste des 210 variables les plus pértinentes obtenues lors d'un projet d'une durée de 3 ans avec beaucoup plus de moyens (temps, ressources, experts médicaux, etc). Comparez cette liste avec les listes obtenues dans ce TP (les 210 obtenus après toute les étapes et les 210 obtenus avec l'ensemble feature selection) et discutez rapidement les résultats. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199cc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des 210 variables\n",
    "# Comparez avec vos données obtenues\n",
    "import pickle\n",
    "\n",
    "# read pickle \n",
    "with open(\"./data/list_210_features.pickle\", \"rb\") as fp:   #Pickling\n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f9eac",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e143fa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60215329",
   "metadata": {},
   "source": [
    "Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
