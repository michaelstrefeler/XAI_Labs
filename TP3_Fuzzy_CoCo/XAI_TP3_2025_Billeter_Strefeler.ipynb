{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7xPWA0whQaI"
   },
   "source": [
    "# XAI 2025 TP3\n",
    "\n",
    "## Features and model selection - Exploration of FuzzyCoCo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-nDzOnXhQaK"
   },
   "source": [
    "\n",
    "\n",
    "Author: Arthur Babey \n",
    "\n",
    "Due: 9 april 2025, 23h59\n",
    "\n",
    "\n",
    "    Based on the work of Diogo Leite (2019), Thibault Showing (2024)\n",
    "    FuzzyCoCo algorithm based on the PhD thesis of Carlos Peña https://infoscience.epfl.ch/record/33110\n",
    "\n",
    "- Professor: Carlos Peña (<a href=\"mailto:carlos.pena@heig-vd.ch\">carlos.pena@heig-vd.ch</a>)\n",
    "- Assistant 2025: Arthur Babey (<a href=\"mailto:arthur.babey@heig-vd.ch\">arthur.babey@heig-vd.ch</a>)\n",
    "\n",
    "Date: Spring 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLBn4w58hQaK"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "Dans ce TP nous allons utiliser [un dataset](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009) contenant, pour différents vins, leur tenneur en certain composés chimiques ainsi qu'une note de qualité. \n",
    "\n",
    "But du TP:\n",
    "\n",
    "0. Mettre en place l'environnement (sur Google Colab si l'installation de FuzzyCoCo ne fonctionne pas localement)\n",
    "1. Explorer FuzzyCoCo sur un dataset simple\n",
    "2. Créer un modèle via grid-search et cross-validation\n",
    "3. Analyser les résultats\n",
    "4. Visualiser les résultats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-5gp2AkhQaM"
   },
   "source": [
    "# 0. Preparatory stage\n",
    "\n",
    "## Set up the environement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab\n",
    "\n",
    "Si vous utilisez Google colab, vous devrez importer les fichiers à chaque exécution et à la fin, veiller à bien sauvegarder votre notebook. La cellule ci-dessous créé les dossiers nécessaires.\n",
    "\n",
    "## Installation de FuzzyCoCoPython\n",
    "\n",
    "Nous allons utilisé une version de FuzzyCoCo disponible sur python grâce à des bindings du code source écris en C et C++, cette version est en cours de développement. Son installation devrait être possible sur toutes les OS mais il est nécessaire d'avoir une version de CMake installé. \n",
    "\n",
    "```\n",
    "pip install git+https://github.com/arthurbabey/fuzzycocopython.git\n",
    "````\n",
    "\n",
    "\n",
    "## Installation de LFA Tools\n",
    "\n",
    "Nous allons également utilisé LFA tools qui est une dépendance à FuzzyCoCoPython. Cette bibliothèque nous aide à simplement visualiser des systèmes flous ainsi nous permet de visualiser les modèles entrainées, des prédictions et l'ensemble des caractéristique des nos modèle de logique floues. \n",
    "\n",
    "```\n",
    "pip install git+https://github.com/arthurbabey/lfa_toolbox.git\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vI95uJwXhQaM"
   },
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNLDT-MAhQaN"
   },
   "source": [
    "## Explore and prepare the dataset\n",
    "\n",
    "\n",
    "The first step is to split our dataset into training and test parts (subsets). Modify this if necessary (shouldn't be).\n",
    "\n",
    "- The path of your original dataset\n",
    "- The path where you want to save the training data\n",
    "- The path where you want to save the test data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "StuUlwD_hQaN",
    "outputId": "2db8e741-68fd-4777-a517-5e36d5876890",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "# Indicate the path of the original DS HERE: \n",
    "# https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009?resource=download\n",
    "\n",
    "csv_path_file_name = './data/winequality-red.csv'\n",
    "\n",
    "data_load = pd.read_csv(csv_path_file_name)\n",
    "data_load.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data source, the quality is a note (integer) between 0 and 10. \n",
    "We will quickly binarize the quality by mapping the note to 0 and 1 using a threshold at 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load[\"quality\"] = (data_load[\"quality\"] >= 6).astype(int)\n",
    "data_load[\"quality\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a binary classification\n",
    "\n",
    "\n",
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train/test split and reshape the data\n",
    "\n",
    "X = data_load.iloc[:, 0:-1]\n",
    "y = data_load.iloc[:,-1]\n",
    "\n",
    "#Split it into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values,random_state=12, test_size=0.33, stratify=y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count occurrences in train and test sets\n",
    "names_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "names_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "# Plot distribution\n",
    "bar_width = 0.4\n",
    "x_labels = np.arange(len(names_train))\n",
    "\n",
    "plt.bar(x_labels - bar_width/2, counts_train, bar_width, label='Train', alpha=0.7)\n",
    "plt.bar(x_labels + bar_width/2, counts_test, bar_width, label='Test', alpha=0.7)\n",
    "\n",
    "plt.xticks(x_labels, names_train)\n",
    "plt.title(\"Train-Test Split\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUAQxFsahQaO"
   },
   "source": [
    "# 1. Training and predicting with FuzzyCoCo\n",
    "\n",
    "FuzzyCoCoPython is being developped to match the scikikt-learn API, thus you can use most of the standard lexic of scikit-learn (fit, predict, score) and most of the methods (grid-search, cross-validation).\n",
    "In the code below you have a description of the (fuzzy logic-based) regression. It is a simple example of how to: \n",
    "\n",
    "- Train a model and make a prediction with it\n",
    "- Save the model in a file\n",
    "- Visualize the resulting model\n",
    "- Visualize the predictions\n",
    "\n",
    "The model bellow is a simple exploration to test two different approaches with FuzzyCoCo. We will optimise the model later. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcFmzBPRhQaO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fuzzycocopython import FuzzyCocoClassifier\n",
    "\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = FuzzyCocoClassifier(nbRules=5, maxGenPop1=20, random_state=1)\n",
    "\n",
    "\n",
    "# Train our classifier and save the model to a file\n",
    "model.fit(X_train, y_train, output_filename='testFuzzySystem.ffs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmP0pMpahQaO"
   },
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the rules\n",
    "\n",
    "model.rules_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fitness curve \n",
    "\n",
    "plot = model.fitness_history_\n",
    "plt.plot(plot)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('Fitness curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the fuzzy sets\n",
    "\n",
    "model.plot_fuzzy_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "\n",
    "- (1 pt) Décrivez les règles du modèle ?\n",
    "\n",
    "\n",
    "- (2 pts) Décrivez et commentez la courbe de la fitness : qu'est ce que cela représente ? a-t-on utilisé un nombre suffisant de générations lors de l'entrainement? \n",
    "\n",
    "\n",
    "- (2 pts) Décrivez les sets de différentes variables, pourquoi ont-ils tous la même forme? que représentent-ils ?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /5 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exploration des paramètres \n",
    "\n",
    "Avec FuzzyCoCo, nous pouvons explorer trois types de paramètres: \n",
    "- Les paramètres de la fitness function qui définisse cette fonction en ajustant les poids des caractéristiques tels que l'accuracy ou la sensitivity. \n",
    "- Les paramètres de l'évolution avec l'algorithme génétique, comme par exemple la taille de la population.\n",
    "- Les paramètres du système flou, comme le nombre de règles maximum ou le nombre de variables par règles. \n",
    "\n",
    "\n",
    "- Explorer les paramètres du système flou:\n",
    "    - [fuzzycoco_base.py](https://github.com/arthurbabey/fuzzycocopython/blob/main/fuzzycocopython/fuzzycoco_base.py)\n",
    "    - [Description des paramètres](fuzzycoco_parameter_description.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- (5 pts) Décrivez les paramètres suivants en une ou deux phrases avec vos propres mots: \n",
    "\n",
    "    - `nbRules`: \n",
    "    - `nbMaxVarPerRule`: \n",
    "    - `nbInSets`:\n",
    "    - `sensitivityW`: \n",
    "    - `maxGenPop1`: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse* :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "\n",
    "En vous basant sur le code donné en exemple [ici](https://github.com/krypty/trefle/blob/5fc398252bbd762c66e12ead9d6295394ac46bd5/examples/grid_search_example.py)\n",
    "\n",
    "Pour la recherche de paramètre vous pouvez utiliser l'API de scikit-learn avec sklearn.model_selection.GridSearchCV. Adaptez vos choix pour que les entrainements ne prenne pas de temps, nous vous conseillons de fixer le nombre de génération à 40 (maxGenPop1) et le nombre de fold à 3 (CV) ceci limitera l'évolution et permet de gagner du temps.\n",
    "\n",
    "\n",
    "- (4 pts) Effectuez une recherche de paramètre (au minimum) les paramètres `nbRules` (3,5 et 6) et `nbMaxVarPerRule` (3, 4 et 5). Vous obtiendrez alors le meilleur système. Vous êtes libres d'explorer d'autres paramètres, si vous voulez y mettre le temps. \n",
    "- (4 pts) Explorez les différents résultats obtenus lors de la recherche de paramètre. Sans aller voir les détails de chaque système testés, quels sont les avantages et les inconvénients de ces différents systèmes en terme d'efficacité et d'interprétabilité en fonction des paramètres? Est-ce que çela se voit dans les résultats?\n",
    "- (4 pts) Affichez le meilleur système (retourné par la grid-search cross-validation) et interprétez le (ses règles). Calculez et commentez sa performance (accuracy, F1 score).\n",
    "- (2 pts) Expliquez ce qu'est la fonction de fitness : quelle importance à-t-elle lors de l'entrainement? comment est-elle influencé par tous les paramètres qui y sont associés (et décrit dans [ce fichier](fuzzycoco_parameter_description.md))\n",
    "\n",
    "\n",
    "**Attention** : pour éviter un run trop long vous pouvez utilisez cv=2 et limitez le nombre de générations possible (maxGenPop1) à quelques dizaines. Cela va impacter négativement l'entrainement mais sinon l'exécution prend trop de temps.\n",
    "\n",
    "*Vous êtes libres de la mise en page de vos réponses, laissez simplement la case pour les corrections à la fin.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# VOTRE CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /19 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Logique flou et explicabilité "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "\n",
    "À partir du dataset de test, sélectionnez quatre points représentatifs :\n",
    "\n",
    "- Vrai positif (TP) : Un point correctement prédit comme positif.\n",
    "- Faux positif (FP) : Un point prédit positif alors qu'il est négatif.\n",
    "- Vrai négatif (TN) : Un point correctement prédit comme négatif.\n",
    "- Faux négatif (FN) : Un point prédit négatif alors qu'il est positif.\n",
    "\n",
    "\n",
    "Pour chaque point sélectionné, effectuez les tâches suivantes :\n",
    "\n",
    "- Visualisation : Utilisez la méthode plot_aggregated_output pour visualiser l'agrégation des règles et la prédiction et/où la méthode predict_with_importances pour obtenir la contribution de chaque règle dans la décision finale.\n",
    "- Explication des règles activées : Identifiez quelles règles (ou quels degrés d'appartenance) sont activées pour le point en question.\n",
    "- Interprétation : Expliquez comment l'activation de ces règles conduit à la prédiction réalisée par le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions \n",
    "\n",
    "> Vrai Positif :\n",
    "\n",
    "Quelles règles ont contribué à la prédiction correcte ?\n",
    "En quoi cette explication renforce-t-elle la confiance dans le modèle ?\n",
    "\n",
    "> Faux Positif :\n",
    "\n",
    "Quelles règles ont conduit à la classification erronée ?\n",
    "\n",
    "> Vrai Négatif :\n",
    "\n",
    "Comment l'absence ou la faiblesse de certaines règles a permis une prédiction négative correcte ?\n",
    "\n",
    "> Faux Négatif :\n",
    "\n",
    "Pourquoi certaines règles n'ont-elles pas suffi à générer une prédiction positive ?\n",
    "\n",
    "> Synthèse Générale :\n",
    "\n",
    "En vous appuyant sur les visualisations et analyses précédentes, expliquez en quoi l'explicabilité du modèle permet de comprendre et, potentiellement, d'améliorer ses performances globales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "\n",
    "- (1 pt) Pourquoi un modèle de logique flou est considéré intérprétable ? \n",
    "\n",
    "\n",
    "- (1 pt) Quels avantages offrent les modèles basés sur des règles par rapport aux modèles « boîte noire » en termes d'explicabilité ?\n",
    "\n",
    "\n",
    "- (1 pt) Quelles sont les limites potentielles de l'interprétabilité dans les modèles de logique flou ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Réservé pour corrections*\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: /20 </b>\n",
    "</div>\n",
    "\n",
    "Commentaires:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIN"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
